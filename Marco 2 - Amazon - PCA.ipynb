{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#adaptacion\n",
    "from utils.adaptacion import pca_grid_search\n",
    "\n",
    "#otros\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import itertools\n",
    "\n",
    "#variables para guardar los resultados\n",
    "tipo = pruebas[3]\n",
    "dataset_name = datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptación\n",
    "\n",
    "## Creación de modelos de adaptación.\n",
    "\n",
    "Por cada par de dominios se entrenan distintos modelos según los parámetros establecidos.\n",
    "Al entrenar cada modelo, este es inmediatamente probado, siendo almacenado o descartado según su desempeño.\n",
    "\n",
    "Cada modelo es guardado en la ruta: models/amazon/pca/me2\\_[dimensiones]\\_[dominio\\_fuente]_[dominio\\_objetivo].pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con el dataset de Amazon (3000 Dimensiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca\n",
      "amazon\n",
      "3000\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print dims\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Amazon\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptando entre:\n",
      "1) electronics - dvd\n",
      "\tn_components: 1500\n",
      "\t0.890\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.884\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.876\n",
      "\n",
      "\tMejor modelo: 0.890\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_electronics_dvd.pkl\n",
      "\n",
      "2) electronics - kitchen\n",
      "\tn_components: 1500\n",
      "\t0.886\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.880\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.875\n",
      "\n",
      "\tMejor modelo: 0.886\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_electronics_kitchen.pkl\n",
      "\n",
      "3) electronics - books\n",
      "\tn_components: 1500\n",
      "\t0.890\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.881\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.874\n",
      "\n",
      "\tMejor modelo: 0.890\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_electronics_books.pkl\n",
      "\n",
      "4) dvd - electronics\n",
      "\tn_components: 1500\n",
      "\t0.824\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.805\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.813\n",
      "\n",
      "\tMejor modelo: 0.824\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_dvd_electronics.pkl\n",
      "\n",
      "5) dvd - kitchen\n",
      "\tn_components: 1500\n",
      "\t0.825\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.803\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.804\n",
      "\n",
      "\tMejor modelo: 0.825\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_dvd_kitchen.pkl\n",
      "\n",
      "6) dvd - books\n",
      "\tn_components: 1500\n",
      "\t0.822\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.811\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.812\n",
      "\n",
      "\tMejor modelo: 0.822\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_dvd_books.pkl\n",
      "\n",
      "7) kitchen - electronics\n",
      "\tn_components: 1500\n",
      "\t0.906\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.903\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.897\n",
      "\n",
      "\tMejor modelo: 0.906\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_kitchen_electronics.pkl\n",
      "\n",
      "8) kitchen - dvd\n",
      "\tn_components: 1500\n",
      "\t0.904\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.900\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.897\n",
      "\n",
      "\tMejor modelo: 0.904\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_kitchen_dvd.pkl\n",
      "\n",
      "9) kitchen - books\n",
      "\tn_components: 1500\n",
      "\t0.902\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.899\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.902\n",
      "\n",
      "\tMejor modelo: 0.902\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_kitchen_books.pkl\n",
      "\n",
      "10) books - electronics\n",
      "\tn_components: 1500\n",
      "\t0.821\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.808\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.810\n",
      "\n",
      "\tMejor modelo: 0.821\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_books_electronics.pkl\n",
      "\n",
      "11) books - dvd\n",
      "\tn_components: 1500\n",
      "\t0.828\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.812\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.806\n",
      "\n",
      "\tMejor modelo: 0.828\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_books_dvd.pkl\n",
      "\n",
      "12) books - kitchen\n",
      "\tn_components: 1500\n",
      "\t0.819\n",
      "\n",
      "\tn_components: 1000\n",
      "\t0.809\n",
      "\n",
      "\tn_components: 750\n",
      "\t0.799\n",
      "\n",
      "\tMejor modelo: 0.819\n",
      "\tGuardando modelo en models/amazon/pca/me2_3000_books_kitchen.pkl\n",
      "\n",
      "\n",
      "Adaptaciones completadas\n"
     ]
    }
   ],
   "source": [
    "models_paths = os.path.join(models_path, dataset_name, tipo, 'me2_%d_models_paths.pkl' % dims)\n",
    "\n",
    "parameters = {\n",
    "    'n_components': [int(dims/2), int(dims/3), int(dims/4)],\n",
    "}\n",
    "\n",
    "pairs = list(itertools.permutations(domains, 2))\n",
    "i = 1\n",
    "\n",
    "#por cada par se entrena un adaptador y se guarda el que mejor resultados entrega\n",
    "print \"Adaptando entre:\"\n",
    "for src, tgt in pairs:\n",
    "    print \"%d) %s - %s\" % (i, src, tgt)\n",
    "    X_src = labeled[src]['X_tr'][:, :dims].todense()\n",
    "    y_src = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_tgt = labeled[tgt]['X_tr'][:, :dims].todense()\n",
    "\n",
    "    X_train = np.concatenate((X_src, X_tgt))\n",
    "\n",
    "    best_model, score = pca_grid_search(X_train, X_src, y_src, parameters, n_jobs=4)\n",
    "    print \"\\tMejor modelo: %.3f\" % score\n",
    "\n",
    "    folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "    prefix = \"me2_%d_%s_%s.pkl\" % (dims, src, tgt)\n",
    "\n",
    "    best_model_save_path = os.path.join(folder_path, prefix)\n",
    "    print \"\\tGuardando modelo en %s\\n\" % best_model_save_path\n",
    "    joblib.dump(best_model, best_model_save_path)\n",
    "    i = i+1\n",
    "\n",
    "print \"\\nAdaptaciones completadas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 2 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 3 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 4 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 5 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 6 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 7 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 8 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 9 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 10 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 11 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 12 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "\n",
      "Pruebas completadas.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=0\n",
    "tareas = len(domains)*(len(domains)-1)\n",
    "pairs = list(itertools.permutations(domains, 2))\n",
    "\n",
    "# por cada par posible para adaptar\n",
    "for src, tgt in pairs:\n",
    "    print \"Tarea %d de %d\" % (i+1, tareas)\n",
    "            \n",
    "    #baseline in-domain error\n",
    "    #e_b(T,T)\n",
    "    #entrenado en dominio tgt y probado en dominio tgt\n",
    "    X_tr = labeled[tgt]['X_tr'][:, :dims].todense()\n",
    "    y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][:, :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    model_name = \"%d_%s.pkl\" % (dims, tgt)\n",
    "    model_path = os.path.join(models_path, dataset_name, \"indomain\", model_name)\n",
    "\n",
    "    #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "    svc = load_best_score(model_path, X_tr, y_tr)\n",
    "    b_error = 1-svc.score(X_ts, y_ts)\n",
    "\n",
    "    #############\n",
    "    #### PCA ####\n",
    "    #############\n",
    "    # se adaptan los dominios usando PCA\n",
    "    print \"Adaptando dominios...\"\n",
    "    folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "    prefix = \"me2_%d_%s_%s.pkl\" % (dims, src, tgt)\n",
    "\n",
    "    best_model_save_path = os.path.join(folder_path, prefix)\n",
    "\n",
    "    best_pca = joblib.load(best_model_save_path)\n",
    "\n",
    "\n",
    "    X_tr = labeled[src]['X_tr'][:, :dims].todense()\n",
    "    X_tr_a = best_pca.transform(X_tr)\n",
    "    y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][:, :dims].todense()\n",
    "    X_ts_a = best_pca.transform(X_ts)\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    clf = get_best_score(X_tr_a, y_tr, classifier='SVC', n_jobs=4)\n",
    "    t_error = 1-clf.score(X_ts_a, y_ts)\n",
    "\n",
    "\n",
    "    # transfer loss t\n",
    "    # t_error - b_error\n",
    "    t_loss = t_error - b_error\n",
    "\n",
    "    tarea = src[0]+'->'+tgt[0]\n",
    "    df.loc[i] = ['PCA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "\n",
    "    i += 1\n",
    "            \n",
    "print \"\\nPruebas completadas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;d</td>\n",
       "      <td>electronics</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>27.385685</td>\n",
       "      <td>11.622791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;k</td>\n",
       "      <td>electronics</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>10.370259</td>\n",
       "      <td>1.782545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;b</td>\n",
       "      <td>electronics</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>29.430736</td>\n",
       "      <td>14.272857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;e</td>\n",
       "      <td>dvd</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>25.290632</td>\n",
       "      <td>14.162854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;k</td>\n",
       "      <td>dvd</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>20.175504</td>\n",
       "      <td>11.587790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;b</td>\n",
       "      <td>dvd</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>26.375659</td>\n",
       "      <td>11.217780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;e</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>12.937823</td>\n",
       "      <td>1.810045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;d</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>27.105678</td>\n",
       "      <td>11.342784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;b</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>30.208255</td>\n",
       "      <td>15.050376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;e</td>\n",
       "      <td>books</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>20.245506</td>\n",
       "      <td>9.117728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;d</td>\n",
       "      <td>books</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>18.355459</td>\n",
       "      <td>2.592565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;k</td>\n",
       "      <td>books</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>21.768044</td>\n",
       "      <td>13.180330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptacion Tarea       Fuente     Objetivo  Baseline error  Transfer error  \\\n",
       "0         PCA  e->d  electronics          dvd       15.762894       27.385685   \n",
       "1         PCA  e->k  electronics      kitchen        8.587715       10.370259   \n",
       "2         PCA  e->b  electronics        books       15.157879       29.430736   \n",
       "3         PCA  d->e          dvd  electronics       11.127778       25.290632   \n",
       "4         PCA  d->k          dvd      kitchen        8.587715       20.175504   \n",
       "5         PCA  d->b          dvd        books       15.157879       26.375659   \n",
       "6         PCA  k->e      kitchen  electronics       11.127778       12.937823   \n",
       "7         PCA  k->d      kitchen          dvd       15.762894       27.105678   \n",
       "8         PCA  k->b      kitchen        books       15.157879       30.208255   \n",
       "9         PCA  b->e        books  electronics       11.127778       20.245506   \n",
       "10        PCA  b->d        books          dvd       15.762894       18.355459   \n",
       "11        PCA  b->k        books      kitchen        8.587715       21.768044   \n",
       "\n",
       "    Transfer loss  \n",
       "0       11.622791  \n",
       "1        1.782545  \n",
       "2       14.272857  \n",
       "3       14.162854  \n",
       "4       11.587790  \n",
       "5       11.217780  \n",
       "6        1.810045  \n",
       "7       11.342784  \n",
       "8       15.050376  \n",
       "9        9.117728  \n",
       "10       2.592565  \n",
       "11      13.180330  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/amazon/pca/me2_3000.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path = os.path.join(scores_path,dataset_name, tipo, \"me2_%d.csv\" % (dims))\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con el dataset de Amazon (1000 Dimensiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca\n",
      "amazon\n",
      "1000\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print dims\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Amazon\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptando entre:\n",
      "1) electronics - dvd\n",
      "\tn_components: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.828\n",
      "\n",
      "\tn_components: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.842\n",
      "\n",
      "\tn_components: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.834\n",
      "\n",
      "\tMejor modelo: 0.842\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_electronics_dvd.pkl\n",
      "\n",
      "2) electronics - kitchen\n",
      "\tn_components: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.833\n",
      "\n",
      "\tn_components: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.834\n",
      "\n",
      "\tn_components: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.847\n",
      "\n",
      "\tMejor modelo: 0.847\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_electronics_kitchen.pkl\n",
      "\n",
      "3) electronics - books\n",
      "\tn_components: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.822\n",
      "\n",
      "\tn_components: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.831\n",
      "\n",
      "\tn_components: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.833\n",
      "\n",
      "\tMejor modelo: 0.833\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_electronics_books.pkl\n",
      "\n",
      "4) dvd - electronics\n",
      "\tn_components: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.794\n",
      "\n",
      "\tn_components: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.796\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.795\n",
      "\n",
      "\tMejor modelo: 0.796\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_dvd_electronics.pkl\n",
      "\n",
      "5) dvd - kitchen\n",
      "\tn_components: 500\n",
      "\t0.772\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.790\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.794\n",
      "\n",
      "\tMejor modelo: 0.794\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_dvd_kitchen.pkl\n",
      "\n",
      "6) dvd - books\n",
      "\tn_components: 500\n",
      "\t0.784\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.777\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.801\n",
      "\n",
      "\tMejor modelo: 0.801\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_dvd_books.pkl\n",
      "\n",
      "7) kitchen - electronics\n",
      "\tn_components: 500\n",
      "\t0.846\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.853\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.848\n",
      "\n",
      "\tMejor modelo: 0.853\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_kitchen_electronics.pkl\n",
      "\n",
      "8) kitchen - dvd\n",
      "\tn_components: 500\n",
      "\t0.846\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.848\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.856\n",
      "\n",
      "\tMejor modelo: 0.856\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_kitchen_dvd.pkl\n",
      "\n",
      "9) kitchen - books\n",
      "\tn_components: 500\n",
      "\t0.840\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.856\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.857\n",
      "\n",
      "\tMejor modelo: 0.857\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_kitchen_books.pkl\n",
      "\n",
      "10) books - electronics\n",
      "\tn_components: 500\n",
      "\t0.771\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.802\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.785\n",
      "\n",
      "\tMejor modelo: 0.802\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_books_electronics.pkl\n",
      "\n",
      "11) books - dvd\n",
      "\tn_components: 500\n",
      "\t0.774\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.794\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.799\n",
      "\n",
      "\tMejor modelo: 0.799\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_books_dvd.pkl\n",
      "\n",
      "12) books - kitchen\n",
      "\tn_components: 500\n",
      "\t0.784\n",
      "\n",
      "\tn_components: 333\n",
      "\t0.785\n",
      "\n",
      "\tn_components: 250\n",
      "\t0.783\n",
      "\n",
      "\tMejor modelo: 0.785\n",
      "\tGuardando modelo en models/amazon/pca/me2_1000_books_kitchen.pkl\n",
      "\n",
      "\n",
      "Adaptaciones completadas\n"
     ]
    }
   ],
   "source": [
    "models_paths = os.path.join(models_path, dataset_name, tipo, 'me2_%d_models_paths.pkl' % dims)\n",
    "\n",
    "parameters = {\n",
    "    'n_components': [int(dims/2), int(dims/3), int(dims/4)],\n",
    "}\n",
    "\n",
    "pairs = list(itertools.permutations(domains, 2))\n",
    "i = 1\n",
    "\n",
    "#por cada par se entrena un adaptador y se guarda el que mejor resultados entrega\n",
    "print \"Adaptando entre:\"\n",
    "for src, tgt in pairs:\n",
    "    print \"%d) %s - %s\" % (i, src, tgt)\n",
    "    X_src = labeled[src]['X_tr'][:, :dims].todense()\n",
    "    y_src = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_tgt = labeled[tgt]['X_tr'][:, :dims].todense()\n",
    "\n",
    "    X_train = np.concatenate((X_src, X_tgt))\n",
    "\n",
    "    best_model, score = pca_grid_search(X_train, X_src, y_src, parameters, n_jobs=4)\n",
    "    print \"\\tMejor modelo: %.3f\" % score\n",
    "\n",
    "    folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "    prefix = \"me2_%d_%s_%s.pkl\" % (dims, src, tgt)\n",
    "\n",
    "    best_model_save_path = os.path.join(folder_path, prefix)\n",
    "    print \"\\tGuardando modelo en %s\\n\" % best_model_save_path\n",
    "    joblib.dump(best_model, best_model_save_path)\n",
    "    i = i+1\n",
    "\n",
    "print \"\\nAdaptaciones completadas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 2 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 3 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 4 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 5 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 6 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 7 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 8 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 9 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 10 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 11 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 12 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "\n",
      "Pruebas completadas.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=0\n",
    "tareas = len(domains)*(len(domains)-1)\n",
    "pairs = list(itertools.permutations(domains, 2))\n",
    "\n",
    "# por cada par posible para adaptar\n",
    "for src, tgt in pairs:\n",
    "    print \"Tarea %d de %d\" % (i+1, tareas)\n",
    "            \n",
    "    #baseline in-domain error\n",
    "    #e_b(T,T)\n",
    "    #entrenado en dominio tgt y probado en dominio tgt\n",
    "    X_tr = labeled[tgt]['X_tr'][:, :dims].todense()\n",
    "    y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][:, :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    model_name = \"%d_%s.pkl\" % (dims, tgt)\n",
    "    model_path = os.path.join(models_path, dataset_name, \"indomain\", model_name)\n",
    "\n",
    "    #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "    svc = load_best_score(model_path, X_tr, y_tr)\n",
    "    b_error = 1-svc.score(X_ts, y_ts)\n",
    "\n",
    "    #############\n",
    "    #### PCA ####\n",
    "    #############\n",
    "    # se adaptan los dominios usando PCA\n",
    "    print \"Adaptando dominios...\"\n",
    "    folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "    prefix = \"me2_%d_%s_%s.pkl\" % (dims, src, tgt)\n",
    "\n",
    "    best_model_save_path = os.path.join(folder_path, prefix)\n",
    "\n",
    "    best_pca = joblib.load(best_model_save_path)\n",
    "\n",
    "\n",
    "    X_tr = labeled[src]['X_tr'][:, :dims].todense()\n",
    "    X_tr_a = best_pca.transform(X_tr)\n",
    "    y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][:, :dims].todense()\n",
    "    X_ts_a = best_pca.transform(X_ts)\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    clf = get_best_score(X_tr_a, y_tr, classifier='SVC', n_jobs=4)\n",
    "    t_error = 1-clf.score(X_ts_a, y_ts)\n",
    "\n",
    "\n",
    "    # transfer loss t\n",
    "    # t_error - b_error\n",
    "    t_loss = t_error - b_error\n",
    "\n",
    "    tarea = src[0]+'->'+tgt[0]\n",
    "    df.loc[i] = ['PCA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "\n",
    "    i += 1\n",
    "            \n",
    "print \"\\nPruebas completadas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;d</td>\n",
       "      <td>electronics</td>\n",
       "      <td>dvd</td>\n",
       "      <td>16.900423</td>\n",
       "      <td>26.840671</td>\n",
       "      <td>9.940249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;k</td>\n",
       "      <td>electronics</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>16.215405</td>\n",
       "      <td>14.762869</td>\n",
       "      <td>-1.452536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;b</td>\n",
       "      <td>electronics</td>\n",
       "      <td>books</td>\n",
       "      <td>23.710593</td>\n",
       "      <td>31.910798</td>\n",
       "      <td>8.200205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;e</td>\n",
       "      <td>dvd</td>\n",
       "      <td>electronics</td>\n",
       "      <td>16.397910</td>\n",
       "      <td>28.853221</td>\n",
       "      <td>12.455311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;k</td>\n",
       "      <td>dvd</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>16.215405</td>\n",
       "      <td>24.558114</td>\n",
       "      <td>8.342709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;b</td>\n",
       "      <td>dvd</td>\n",
       "      <td>books</td>\n",
       "      <td>23.710593</td>\n",
       "      <td>23.230581</td>\n",
       "      <td>-0.480012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;e</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>electronics</td>\n",
       "      <td>16.397910</td>\n",
       "      <td>17.910448</td>\n",
       "      <td>1.512538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;d</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>dvd</td>\n",
       "      <td>16.900423</td>\n",
       "      <td>27.788195</td>\n",
       "      <td>10.887772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;b</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>books</td>\n",
       "      <td>23.710593</td>\n",
       "      <td>32.783320</td>\n",
       "      <td>9.072727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;e</td>\n",
       "      <td>books</td>\n",
       "      <td>electronics</td>\n",
       "      <td>16.397910</td>\n",
       "      <td>26.215655</td>\n",
       "      <td>9.817745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;d</td>\n",
       "      <td>books</td>\n",
       "      <td>dvd</td>\n",
       "      <td>16.900423</td>\n",
       "      <td>18.957974</td>\n",
       "      <td>2.057551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;k</td>\n",
       "      <td>books</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>16.215405</td>\n",
       "      <td>28.188205</td>\n",
       "      <td>11.972799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptacion Tarea       Fuente     Objetivo  Baseline error  Transfer error  \\\n",
       "0         PCA  e->d  electronics          dvd       16.900423       26.840671   \n",
       "1         PCA  e->k  electronics      kitchen       16.215405       14.762869   \n",
       "2         PCA  e->b  electronics        books       23.710593       31.910798   \n",
       "3         PCA  d->e          dvd  electronics       16.397910       28.853221   \n",
       "4         PCA  d->k          dvd      kitchen       16.215405       24.558114   \n",
       "5         PCA  d->b          dvd        books       23.710593       23.230581   \n",
       "6         PCA  k->e      kitchen  electronics       16.397910       17.910448   \n",
       "7         PCA  k->d      kitchen          dvd       16.900423       27.788195   \n",
       "8         PCA  k->b      kitchen        books       23.710593       32.783320   \n",
       "9         PCA  b->e        books  electronics       16.397910       26.215655   \n",
       "10        PCA  b->d        books          dvd       16.900423       18.957974   \n",
       "11        PCA  b->k        books      kitchen       16.215405       28.188205   \n",
       "\n",
       "    Transfer loss  \n",
       "0        9.940249  \n",
       "1       -1.452536  \n",
       "2        8.200205  \n",
       "3       12.455311  \n",
       "4        8.342709  \n",
       "5       -0.480012  \n",
       "6        1.512538  \n",
       "7       10.887772  \n",
       "8        9.072727  \n",
       "9        9.817745  \n",
       "10       2.057551  \n",
       "11      11.972799  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/amazon/pca/me2_1000.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path = os.path.join(scores_path,dataset_name, tipo, \"me2_%d.csv\" % (dims))\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
