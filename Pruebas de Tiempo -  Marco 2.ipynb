{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#otros\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "#variables para guardar los resultados\n",
    "tipo = pruebas[0]\n",
    "dataset_name = datasets[0]\n",
    "dims = dimensions[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "amazon\n",
      "3000\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print dims\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con el dataset Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El formato de cada prueba es:\n",
    "\n",
    "* nombre_prueba (parámetro=valor)\n",
    " \n",
    "#### Por ejemplo, para la prueba de mSDA con 5 capas, el nombre es:\n",
    "\n",
    "* mSDA (l=5)\n",
    "\n",
    "#### Las pruebas para cada método son:\n",
    "\n",
    "* SDA: Cantidad de capas entre {1, 3, 5} con la mitad de la dimensionalidad original por cada capa y cantidad de epochs entre {25, 50}.\n",
    "* mSDA: Cantidad de capas entre {1, 3, 5}.\n",
    "* PCA: Ejecuciones cambiando la dimensionalidad a 1/2 y 1/4 de la original.\n",
    "* GFK: Pruebas con cantidad de sub-dimensiones entre {10, 50, 100}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Amazon\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "unlabeled = dataset_object.unlabeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27677, 3000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset_object.get_all_X()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GFK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.adaptacion import adapt_gfk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_times_path = os.path.join(times_path, \"me2_gfk.csv\")\n",
    "\n",
    "if os.path.exists(new_times_path):\n",
    "    df_gfk = pd.read_csv(new_times_path)\n",
    "    i = df_gfk.shape[0]\n",
    "else:\n",
    "    df_gfk = pd.DataFrame(columns=dataframe_time_columns)\n",
    "    i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size_dims = int(dims/2)\n",
    "n_subs = [10, 50, 100]\n",
    "\n",
    "tgt = domains[0]\n",
    "src = domains[1]\n",
    "\n",
    "X_tr = np.asarray(labeled[tgt]['X_tr'].todense())\n",
    "y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "X_ts = np.asarray(labeled[tgt]['X_ts'].todense())\n",
    "y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runs = 5\n",
    "\n",
    "for j in xrange(runs):\n",
    "    print j+1\n",
    "    for n in n_subs:\n",
    "        t_inicio = timeit.default_timer()\n",
    "\n",
    "        nombre = \"GFK (n_dims=%d)\" % n\n",
    "        print nombre\n",
    "\n",
    "        adapt_gfk(X_tr, X_ts, n, size_dims)\n",
    "        \n",
    "        t_fin = timeit.default_timer()\n",
    "        tiempo = (t_fin-t_inicio)/60.\n",
    "\n",
    "        print \"\\tEntrenado en %.3fm\" % tiempo\n",
    "\n",
    "        df_gfk.loc[i] = [nombre, tiempo]\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gfk = df_gfk.groupby('Adaptacion').mean().reset_index()\n",
    "df_gfk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Guardando en %s\" % new_times_path\n",
    "df_gfk.to_csv(new_times_path)\n",
    "print \"Resultados guardados.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mSDA Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mSDA.msda_theano import mSDATheano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_times_path = os.path.join(times_path, \"me2_msda.csv\")\n",
    "\n",
    "if os.path.exists(new_times_path):\n",
    "    df_msda = pd.read_csv(new_times_path)\n",
    "    i = df_msda.shape[0]\n",
    "else:\n",
    "    df_msda = pd.DataFrame(columns=dataframe_time_columns)\n",
    "    i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = [1, 3, 5]\n",
    "x = T.dmatrix('x')\n",
    "runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in xrange(runs):\n",
    "    print j+1\n",
    "    for layer in layers:\n",
    "        nombre = \"mSDA (l=%d)\" % layer\n",
    "        print nombre\n",
    "\n",
    "        msda = mSDATheano(x, layer, 0.3)\n",
    "        tiempo = msda.fit(X)\n",
    "\n",
    "        df_msda.loc[i] = [nombre, tiempo]\n",
    "\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_msda = df_msda.groupby('Adaptacion').mean().reset_index()\n",
    "df_msda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Guardando en %s\" % new_times_path\n",
    "df_msda.to_csv(new_times_path)\n",
    "print \"Resultados guardados.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.adaptacion import create_SDA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_times_path = os.path.join(times_path, \"me2_sda.csv\")\n",
    "\n",
    "if os.path.exists(new_times_path):\n",
    "    df_sda = pd.read_csv(new_times_path)\n",
    "    i = df_sda.shape[0]\n",
    "else:\n",
    "    df_sda = pd.DataFrame(columns=dataframe_time_columns)\n",
    "    i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# se divide el dataset para los datos de entrenamiento y validacion del SDA\n",
    "X_train, X_val, _, _ = train_test_split(X, np.zeros(X.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "print X_train.shape\n",
    "print X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = [[dims/2],\n",
    "          [dims/2, dims/2, dims/2],\n",
    "          [dims/2, dims/2, dims/2, dims/2, dims/2]]\n",
    "\n",
    "epochs = [25, 50]\n",
    "runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in xrange(runs):\n",
    "    print j+1\n",
    "    for epoch in epochs:\n",
    "        for layer in layers:\n",
    "            nombre = \"SDA (l=%d, epochs=%d)\" % (len(layer), epoch)\n",
    "            print nombre\n",
    "\n",
    "            autoencoder, encoder = create_SDA(X_train.shape[1], layer, 0.3)\n",
    "\n",
    "            t_inicio = timeit.default_timer()\n",
    "\n",
    "            print \"\\tEntrenando autoencoder...\"\n",
    "            autoencoder.fit(X_train, X_train,\n",
    "               epochs=epoch,\n",
    "               batch_size=256,\n",
    "               shuffle=True,\n",
    "               verbose=0,\n",
    "               validation_data=(X_val, X_val))\n",
    "\n",
    "            t_fin = timeit.default_timer()\n",
    "\n",
    "            tiempo = (t_fin - t_inicio)/60.\n",
    "            print \"\\tEntrenado en %.3fm\" % tiempo\n",
    "\n",
    "            df_sda.loc[i] = [nombre, tiempo]\n",
    "\n",
    "            i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sda = df_sda.groupby('Adaptacion').mean().reset_index()\n",
    "df_sda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Guardando en %s\" % new_times_path\n",
    "df_sda.to_csv(new_times_path)\n",
    "print \"Resultados guardados.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_times_path = os.path.join(times_path, \"me2_pca.csv\")\n",
    "\n",
    "if os.path.exists(new_times_path):\n",
    "    df_pca = pd.read_csv(new_times_path)\n",
    "    i = df_pca.shape[0]\n",
    "else:\n",
    "    df_pca = pd.DataFrame(columns=dataframe_time_columns)\n",
    "    i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = [dims/2, dims/4]\n",
    "runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in xrange(5):\n",
    "    print j+1\n",
    "    for n in n_components:\n",
    "        nombre = \"PCA (n=%d)\" % n\n",
    "        print \"\\t%s\" % nombre\n",
    "\n",
    "        new_model = PCA(n_components=n)\n",
    "        \n",
    "        t_inicio = timeit.default_timer()\n",
    "        new_model.fit(X)\n",
    "        t_fin = timeit.default_timer()\n",
    "\n",
    "        tiempo = (t_fin - t_inicio)/60.\n",
    "        print \"\\tEntrenado en %.3fm\" % tiempo\n",
    "        \n",
    "        df_pca.loc[i] = [nombre, tiempo]\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca = df_pca.groupby('Adaptacion').mean().reset_index()\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Guardando en %s\" % new_times_path\n",
    "df_pca.to_csv(new_times_path)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
