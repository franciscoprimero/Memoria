{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter - Baseline\n",
    "\n",
    "### Pruebas con los distintos clasificadores para obtener los valores de transfer loss sin realizar adaptacion entre dominios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#otros\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "#variables para guardar los resultados\n",
    "tipo = pruebas[0]\n",
    "dataset_name = datasets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "twitter\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con el dataset Twitter (2000 Dimensiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Twitter\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando dominio 1 de 3: rio2016\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Score: 0.898\n",
      "Entrenando dominio 2 de 3: thevoice\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Score: 0.926\n",
      "Entrenando dominio 3 de 3: general\n",
      "Creando mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando mejor modelo.\n",
      "Score: 0.730\n",
      "\n",
      "Tarea terminada.\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "for tgt in domains:\n",
    "    print \"Entrenando dominio %d de %d: %s\" % (i, len(domains), tgt)\n",
    "    X_tr = labeled[tgt]['X_tr'][: , :dims].todense()\n",
    "    y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][: , :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    ruta_modelo = os.path.join(models_path, dataset_name, \"indomain\", \"%d_%s.pkl\" % (dims, tgt))\n",
    "\n",
    "    #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "    svc = load_best_score(ruta_modelo, X_tr, y_tr)\n",
    "    \n",
    "    print \"Score: %.3f\" % svc.score(X_ts, y_ts)\n",
    "    i = i+1\n",
    "    \n",
    "print \"\\nTarea terminada.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 6\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 2 de 6\n",
      "Creando mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando mejor modelo.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 3 de 6\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 4 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 5 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando mejor modelo.\n",
      "Tarea 6 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando mejor modelo.\n",
      "\n",
      "Pruebas completadas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=0\n",
    "tareas = len(domains)*(len(domains)-1)\n",
    "pairs = list(itertools.permutations(domains, 2))\n",
    "\n",
    "# por cada par posible para adaptar\n",
    "for src, tgt in pairs:\n",
    "    print \"Tarea %d de %d\" % (i+1, tareas)\n",
    "            \n",
    "    #baseline in-domain error\n",
    "    #e_b(T,T)\n",
    "    #entrenado en dominio tgt y probado en dominio tgt\n",
    "    X_tr = labeled[tgt]['X_tr'][: , :dims].todense()\n",
    "    y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][: , :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    model_name = \"%d_%s.pkl\" % (dims, tgt)\n",
    "    model_path = os.path.join(models_path, dataset_name, \"indomain\",model_name)\n",
    "\n",
    "    #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "    svc = load_best_score(model_path, X_tr, y_tr)\n",
    "    b_error = 1-svc.score(X_ts, y_ts)\n",
    "\n",
    "\n",
    "    #transfer error\n",
    "    #entrenado en dominio src y probado en dominio tgt sin adaptar\n",
    "    X_tr = labeled[src]['X_tr'][: , :dims].todense()\n",
    "    y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][: , :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "    \n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    model_name = \"%d_%s_%s.pkl\" % (dims, src, tgt)\n",
    "    model_path = os.path.join(models_path, dataset_name, tipo, model_name)\n",
    "\n",
    "    svc2 = load_best_score(model_path, X_tr, y_tr)\n",
    "    t_error = 1-svc2.score(X_ts, y_ts)\n",
    "\n",
    "    # transfer loss t\n",
    "    # t_error - b_error\n",
    "    t_loss = t_error - b_error\n",
    "\n",
    "    tarea = src[0]+'->'+tgt[0]\n",
    "    df.loc[i] = ['Baseline',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "    i+=1\n",
    "\n",
    "print \"\\nPruebas completadas.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>r-&gt;t</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>7.362689</td>\n",
       "      <td>20.845170</td>\n",
       "      <td>13.482481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>r-&gt;g</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>general</td>\n",
       "      <td>26.998127</td>\n",
       "      <td>43.116491</td>\n",
       "      <td>16.118364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>t-&gt;r</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>10.208711</td>\n",
       "      <td>13.747731</td>\n",
       "      <td>3.539020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>t-&gt;g</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>general</td>\n",
       "      <td>26.998127</td>\n",
       "      <td>39.874641</td>\n",
       "      <td>12.876514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>g-&gt;r</td>\n",
       "      <td>general</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>10.208711</td>\n",
       "      <td>24.183303</td>\n",
       "      <td>13.974592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>g-&gt;t</td>\n",
       "      <td>general</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>7.362689</td>\n",
       "      <td>23.236269</td>\n",
       "      <td>15.873580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Adaptacion Tarea    Fuente  Objetivo  Baseline error  Transfer error  \\\n",
       "0   Baseline  r->t   rio2016  thevoice        7.362689       20.845170   \n",
       "1   Baseline  r->g   rio2016   general       26.998127       43.116491   \n",
       "2   Baseline  t->r  thevoice   rio2016       10.208711       13.747731   \n",
       "3   Baseline  t->g  thevoice   general       26.998127       39.874641   \n",
       "4   Baseline  g->r   general   rio2016       10.208711       24.183303   \n",
       "5   Baseline  g->t   general  thevoice        7.362689       23.236269   \n",
       "\n",
       "   Transfer loss  \n",
       "0      13.482481  \n",
       "1      16.118364  \n",
       "2       3.539020  \n",
       "3      12.876514  \n",
       "4      13.974592  \n",
       "5      15.873580  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/twitter/baseline/me1_2000.csv\n",
      "Guardando en scores/twitter/baseline/me2_2000.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path1 = os.path.join(scores_path,dataset_name, tipo, \"me1_%d.csv\" % (dims))\n",
    "new_scores_path2 = os.path.join(scores_path,dataset_name, tipo, \"me2_%d.csv\" % (dims))\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path1\n",
    "print \"Guardando en %s\" % new_scores_path2\n",
    "\n",
    "df.to_csv(new_scores_path1, columns=df.columns)\n",
    "df.to_csv(new_scores_path2, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con el dataset Twitter (1000 Dimensiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Twitter\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando dominio 1 de 3: rio2016\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Score: 0.926\n",
      "Entrenando dominio 2 de 3: thevoice\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Score: 0.810\n",
      "Entrenando dominio 3 de 3: general\n",
      "Creando mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando mejor modelo.\n",
      "Score: 0.696\n",
      "\n",
      "Tarea terminada.\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "for tgt in domains:\n",
    "    print \"Entrenando dominio %d de %d: %s\" % (i, len(domains), tgt)\n",
    "    X_tr = labeled[tgt]['X_tr'][: , :dims].todense()\n",
    "    y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][: , :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    ruta_modelo = os.path.join(models_path, dataset_name, \"indomain\", \"%d_%s.pkl\" % (dims, tgt))\n",
    "\n",
    "    #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "    svc = load_best_score(ruta_modelo, X_tr, y_tr)\n",
    "    \n",
    "    print \"Score: %.3f\" % svc.score(X_ts, y_ts)\n",
    "    i = i+1\n",
    "    \n",
    "print \"\\nTarea terminada.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 2 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 3 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 4 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n",
      "Guardando mejor modelo.\n",
      "Tarea 5 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando mejor modelo.\n",
      "Tarea 6 de 6\n",
      "Cargando modelo existente.\n",
      "Creando mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando mejor modelo.\n",
      "\n",
      "Pruebas completadas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=0\n",
    "tareas = len(domains)*(len(domains)-1)\n",
    "pairs = list(itertools.permutations(domains, 2))\n",
    "\n",
    "# por cada par posible para adaptar\n",
    "for src, tgt in pairs:\n",
    "    print \"Tarea %d de %d\" % (i+1, tareas)\n",
    "            \n",
    "    #baseline in-domain error\n",
    "    #e_b(T,T)\n",
    "    #entrenado en dominio tgt y probado en dominio tgt\n",
    "    X_tr = labeled[tgt]['X_tr'][: , :dims].todense()\n",
    "    y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][: , :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    model_name = \"%d_%s.pkl\" % (dims, tgt)\n",
    "    model_path = os.path.join(models_path, dataset_name, \"indomain\",model_name)\n",
    "\n",
    "    #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "    svc = load_best_score(model_path, X_tr, y_tr)\n",
    "    b_error = 1-svc.score(X_ts, y_ts)\n",
    "\n",
    "\n",
    "    #transfer error\n",
    "    #entrenado en dominio src y probado en dominio tgt sin adaptar\n",
    "    X_tr = labeled[src]['X_tr'][: , :dims].todense()\n",
    "    y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = labeled[tgt]['X_ts'][: , :dims].todense()\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "    \n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    model_name = \"%d_%s_%s.pkl\" % (dims, src, tgt)\n",
    "    model_path = os.path.join(models_path, dataset_name, tipo, model_name)\n",
    "\n",
    "    svc2 = load_best_score(model_path, X_tr, y_tr)\n",
    "    t_error = 1-svc2.score(X_ts, y_ts)\n",
    "\n",
    "    # transfer loss t\n",
    "    # t_error - b_error\n",
    "    t_loss = t_error - b_error\n",
    "\n",
    "    tarea = src[0]+'->'+tgt[0]\n",
    "    df.loc[i] = ['Baseline',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "    i+=1\n",
    "\n",
    "print \"\\nPruebas completadas.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>r-&gt;t</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>19.045928</td>\n",
       "      <td>22.289299</td>\n",
       "      <td>3.243371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>r-&gt;g</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>general</td>\n",
       "      <td>30.407980</td>\n",
       "      <td>42.988882</td>\n",
       "      <td>12.580903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>t-&gt;r</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>7.372958</td>\n",
       "      <td>18.534483</td>\n",
       "      <td>11.161525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>t-&gt;g</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>general</td>\n",
       "      <td>30.407980</td>\n",
       "      <td>42.451826</td>\n",
       "      <td>12.043846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>g-&gt;r</td>\n",
       "      <td>general</td>\n",
       "      <td>rio2016</td>\n",
       "      <td>7.372958</td>\n",
       "      <td>17.082577</td>\n",
       "      <td>9.709619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>g-&gt;t</td>\n",
       "      <td>general</td>\n",
       "      <td>thevoice</td>\n",
       "      <td>19.045928</td>\n",
       "      <td>24.076705</td>\n",
       "      <td>5.030777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Adaptacion Tarea    Fuente  Objetivo  Baseline error  Transfer error  \\\n",
       "0   Baseline  r->t   rio2016  thevoice       19.045928       22.289299   \n",
       "1   Baseline  r->g   rio2016   general       30.407980       42.988882   \n",
       "2   Baseline  t->r  thevoice   rio2016        7.372958       18.534483   \n",
       "3   Baseline  t->g  thevoice   general       30.407980       42.451826   \n",
       "4   Baseline  g->r   general   rio2016        7.372958       17.082577   \n",
       "5   Baseline  g->t   general  thevoice       19.045928       24.076705   \n",
       "\n",
       "   Transfer loss  \n",
       "0       3.243371  \n",
       "1      12.580903  \n",
       "2      11.161525  \n",
       "3      12.043846  \n",
       "4       9.709619  \n",
       "5       5.030777  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/twitter/baseline/me1_1000.csv\n",
      "Guardando en scores/twitter/baseline/me2_1000.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path1 = os.path.join(scores_path,dataset_name, tipo, \"me1_%d.csv\" % (dims))\n",
    "new_scores_path2 = os.path.join(scores_path,dataset_name, tipo, \"me2_%d.csv\" % (dims))\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path1\n",
    "print \"Guardando en %s\" % new_scores_path2\n",
    "\n",
    "df.to_csv(new_scores_path1, columns=df.columns)\n",
    "df.to_csv(new_scores_path2, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
