{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_amazon_file(path, labeled=True):\n",
    "    \"\"\"read_amazon_file.\"\"\"\n",
    "    file = open(path)\n",
    "    comentarios = []\n",
    "    labels = []\n",
    "    for line in file:\n",
    "        line = line.split(\"#label#:\")\n",
    "        labels.append(line[1][:-1])\n",
    "\n",
    "        pares = line[0].split(\" \")\n",
    "        comentario = \"\"\n",
    "        for par in pares:\n",
    "            palabra = par.split(\":\")[0]\n",
    "            palabra = str.replace(palabra, \"_\", \" \")\n",
    "            comentario = comentario + palabra + \" \"\n",
    "        comentario = comentario + \".\"\n",
    "        comentarios.append(comentario)\n",
    "\n",
    "    if labeled:\n",
    "        return comentarios, labels\n",
    "    else:\n",
    "        return comentarios\n",
    "\n",
    "def read_all_amazon_domains(path):\n",
    "    \"\"\"read_all_amazon_domains.\"\"\"\n",
    "    file_names = ['positive.review', 'negative.review', 'unlabeled.review']\n",
    "\n",
    "    domains = []\n",
    "\n",
    "    labeled = {}\n",
    "    unlabeled = {}\n",
    "\n",
    "    print 'Leyendo dominio: '\n",
    "    for folder in os.listdir(path):\n",
    "        print \"- %s\" % folder\n",
    "\n",
    "        instances = []\n",
    "        labels = []\n",
    "        for file_name in file_names[0:2]:\n",
    "            file_path = os.path.join(path, folder, file_name)\n",
    "            new_instances, new_labels = read_amazon_file(file_path)\n",
    "            instances += new_instances\n",
    "            labels += new_labels\n",
    "\n",
    "        labeled[folder] = {\n",
    "            'X': instances,\n",
    "            'y': labels,\n",
    "        }\n",
    "\n",
    "        # datos sin etiquetas\n",
    "        file_path = os.path.join(path, folder, file_names[2])\n",
    "        instances = read_amazon_file(file_path, labeled=False)\n",
    "\n",
    "        unlabeled[folder] = {\n",
    "            'X': instances,\n",
    "        }\n",
    "\n",
    "        domains.append(folder)\n",
    "\n",
    "    return labeled, unlabeled, domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocesar(labeled, unlabeled, dims, stop_words=None):\n",
    "    \"\"\"preprocesar.\"\"\"\n",
    "\n",
    "    instances = []\n",
    "    labels = []\n",
    "    ant = 0\n",
    "    labeled_lims ={}\n",
    "    unlabeled_lims = {}\n",
    "\n",
    "    for v_l in labeled.values():\n",
    "        instances += v_l['X']\n",
    "        labels += v_l['y']\n",
    "\n",
    "    if unlabeled is not None:\n",
    "        for v_ul in unlabeled.values():\n",
    "            instances += v_ul['X']\n",
    "\n",
    "\n",
    "\n",
    "    x_cv = CountVectorizer(max_features=dims, ngram_range=(1, 2), binary=True, stop_words=stop_words)\n",
    "    x_cv.fit(instances)\n",
    "\n",
    "    y_cv = CountVectorizer()\n",
    "    y_cv.fit(labels)\n",
    "\n",
    "\n",
    "    for d_l in labeled:\n",
    "        labeled[d_l]['X'] = x_cv.transform(labeled[d_l]['X'])\n",
    "        labeled[d_l]['y'] = y_cv.transform(labeled[d_l]['y'])\n",
    "\n",
    "    if unlabeled is not None:\n",
    "        for d_ul in unlabeled:\n",
    "            unlabeled[d_ul]['X'] = x_cv.transform(labeled[d_ul]['X'])\n",
    "\n",
    "    return labeled, unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw_data/multi-domain/processed_acl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(raw_path, raw_folders['amazon'])\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo dominio: \n",
      "- electronics\n",
      "- dvd\n",
      "- kitchen\n",
      "- books\n"
     ]
    }
   ],
   "source": [
    "labeled, unlabeled, domains = read_all_amazon_domains(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "labels = []\n",
    "ant = 0\n",
    "labeled_lims ={}\n",
    "unlabeled_lims = {}\n",
    "\n",
    "for v_l in labeled.values():\n",
    "    instances += v_l['X']\n",
    "    labels += v_l['y']\n",
    "\n",
    "if unlabeled is not None:\n",
    "    for v_ul in unlabeled.values():\n",
    "        instances += v_ul['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "x_cv = CountVectorizer(max_features=200, ngram_range=(1, 2), binary=True, stop_words=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "dims = 200\n",
    "stop_words = None\n",
    "x2 = HashingVectorizer(stop_words=stop_words, n_features=dims, binary=True, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = x2.fit_transform(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27677x200 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 3824700 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled, unlabeled = preprocesar(labeled, unlabeled, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
