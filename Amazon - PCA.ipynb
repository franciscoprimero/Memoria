{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#adaptacion\n",
    "from utils.adaptacion import pca_pseudo_grid_search\n",
    "\n",
    "#otros\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "tipo = pruebas[3]\n",
    "dataset_name = datasets[0]\n",
    "dims = dimensions[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con el dataset de Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca\n",
      "amazon\n",
      "3000\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print dims\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Twitter\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los datos disponibles obtenidos\n"
     ]
    }
   ],
   "source": [
    "# se obtienen todos los valores X disponibles para realizar adaptacion\n",
    "X = dataset_object.get_all_X()\n",
    "X = np.asarray(X)\n",
    "\n",
    "print \"Todos los datos disponibles obtenidos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "saved_paths = [ruta_1,...,ruta_n]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando modelos de adaptacion...\n",
      "\tn_components: 1500\n",
      "\tEntrenando modelo PCA...\n",
      "\tGuardando modelo en models/pca/amazon_0.pkl\n",
      "\n",
      "\tn_components: 1000\n",
      "\tEntrenando modelo PCA...\n",
      "\tGuardando modelo en models/pca/amazon_1.pkl\n",
      "\n",
      "\tn_components: 750\n",
      "\tEntrenando modelo PCA...\n",
      "\tGuardando modelo en models/pca/amazon_2.pkl\n",
      "\n",
      "Modelos creados.\n",
      "\n",
      "Guardando rutas en models/pca/amazon_paths.pkl\n",
      "Creacion de modelos realizada en 1.63m\n"
     ]
    }
   ],
   "source": [
    "t_total_i = timeit.default_timer()\n",
    "\n",
    "pca_paths = os.path.join(models_path, tipo, \"%s_paths.pkl\" % dataset_name)\n",
    "\n",
    "if os.path.exists(pca_paths):\n",
    "    print \"Cargando rutas de modelos adaptados.\"\n",
    "    saved_paths = joblib.load(pca_paths)\n",
    "else:\n",
    "    print \"Creando modelos de adaptacion...\"\n",
    "\n",
    "    n_components = [int(dims/2), int(dims/3), int(dims/4)]\n",
    "\n",
    "    parametros = {\n",
    "        'n_components': n_components\n",
    "    }\n",
    "\n",
    "\n",
    "    saved_paths = pca_pseudo_grid_search(X, parametros, models_path, tipo, dataset_name)\n",
    "\n",
    "    print \"Modelos creados.\\n\"\n",
    "    \n",
    "    joblib.dump(saved_paths, pca_paths)\n",
    "    print \"Guardando rutas en %s\" % pca_paths\n",
    "    \n",
    "t_total_f = timeit.default_timer()\n",
    "\n",
    "t_total = (t_total_f - t_total_i)/60.\n",
    "\n",
    "print \"Creacion de modelos realizada en %.2fm\" % t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/pca/amazon_0.pkl',\n",
       " 'models/pca/amazon_1.pkl',\n",
       " 'models/pca/amazon_2.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "domain_msda_paths = [ruta_1,...,ruta_n]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo mejor clasificador para electronics\n",
      "Sin adaptar: 0.8187\n",
      "1) n_components=1500  score: 0.8119\n",
      "2) n_components=1000  score: 0.8137\n",
      "3) n_components=750  score: 0.8063\n",
      "\n",
      "\tMejor modelo: n_components=1000\n",
      "\tGuardando en models/pca/amazon_electronics.pkl\n",
      "\n",
      "Obteniendo mejor clasificador para dvd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=20000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin adaptar: 0.7644\n",
      "1) n_components=1500  score: 0.7531\n",
      "2) n_components=1000  score: 0.7500\n",
      "3) n_components=750  score: 0.7375\n",
      "\n",
      "\tMejor modelo: n_components=1500\n",
      "\tGuardando en models/pca/amazon_dvd.pkl\n",
      "\n",
      "Obteniendo mejor clasificador para kitchen\n",
      "Sin adaptar: 0.8419\n",
      "1) n_components=1500  score: 0.8244\n",
      "2) n_components=1000  score: 0.8225\n",
      "3) n_components=750  score: 0.8206\n",
      "\n",
      "\tMejor modelo: n_components=1500\n",
      "\tGuardando en models/pca/amazon_kitchen.pkl\n",
      "\n",
      "Obteniendo mejor clasificador para books\n",
      "Sin adaptar: 0.7600\n",
      "1) n_components=1500  score: 0.7475\n",
      "2) n_components=1000  score: 0.7425\n",
      "3) n_components=750  score: 0.7312\n",
      "\n",
      "\tMejor modelo: n_components=1500\n",
      "\tGuardando en models/pca/amazon_books.pkl\n",
      "\n",
      "Guardando rutas en models/pca/best_amazon_paths.pkl\n",
      "\n",
      "Obtencion de los mejores modelos terminada.\n"
     ]
    }
   ],
   "source": [
    "best_pca_paths = os.path.join(models_path, tipo, \"best_%s_paths.pkl\" % dataset_name )\n",
    "\n",
    "if os.path.exists(best_pca_paths):\n",
    "    #se cargan las rutas de los modelos guardados\n",
    "    domain_pca_paths = joblib.load(best_pca_paths)   \n",
    "\n",
    "else:\n",
    "    domain_pca_paths = []\n",
    "    #se obtienen los mejores modelos \n",
    "    for domain in domains:\n",
    "        # se obtienen los datos del dominio\n",
    "        X_tr = np.asarray(labeled[domain]['X_tr'].todense())\n",
    "        y_tr = np.asarray(labeled[domain]['y_tr'].todense()).argmax(axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print \"Obteniendo mejor clasificador para %s\" % domain\n",
    "        \n",
    "        new_clf = get_best_score(X_tr, y_tr, clasifier='SVC', n_jobs=4)\n",
    "        new_score = new_clf.best_score_\n",
    "        \n",
    "        print \"Sin adaptar: %.4f\" % (new_score)\n",
    "        \n",
    "        i = 1\n",
    "\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        for pca_model_path in saved_paths:\n",
    "            \n",
    "            pca_model = joblib.load(pca_model_path)\n",
    "            n_components = pca_model.n_components_\n",
    "            \n",
    "            print \"%d) n_components=%d \" % (i, n_components),\n",
    "\n",
    "            # se adaptan los datos\n",
    "            X_deep = pca_model.transform(X_tr)\n",
    "\n",
    "            # se obtiene el mejor score con GridSearch\n",
    "            new_clf = get_best_score(X_deep, y_tr, clasifier='SVC', n_jobs=4)\n",
    "            new_score = new_clf.best_score_\n",
    "            print \"score: %.4f\" % new_score\n",
    "            # se guarda si es el mejor para el modelo\n",
    "            if new_score > best_score:\n",
    "                best_score = new_score\n",
    "                best_model = pca_model\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "        #se guarda el mejor modelo para este dominio\n",
    "        print \"\\n\\tMejor modelo: n_components=%d\" % (best_model.n_components_)\n",
    "        best_pca_path = os.path.join(models_path, tipo, \"%s_%s.pkl\" % (dataset_name, domain))\n",
    "        print \"\\tGuardando en %s\\n\" % best_pca_path\n",
    "        joblib.dump(best_model, best_pca_path)\n",
    "        \n",
    "        domain_pca_paths.append(best_pca_path)\n",
    "    \n",
    "    print \"Guardando rutas en %s\" % best_pca_paths\n",
    "    joblib.dump(domain_pca_paths, best_pca_paths)\n",
    "\n",
    "print \"\\nObtencion de los mejores modelos terminada.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/pca/amazon_electronics.pkl',\n",
       " 'models/pca/amazon_dvd.pkl',\n",
       " 'models/pca/amazon_kitchen.pkl',\n",
       " 'models/pca/amazon_books.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_pca_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/pca/amazon_electronics.pkl\n",
      "Cargando mejor modelo para electronics\n",
      "\tAdaptando dominio\n",
      "models/pca/amazon_dvd.pkl\n",
      "Cargando mejor modelo para dvd\n",
      "\tAdaptando dominio\n",
      "models/pca/amazon_kitchen.pkl\n",
      "Cargando mejor modelo para kitchen\n",
      "\tAdaptando dominio\n",
      "models/pca/amazon_books.pkl\n",
      "Cargando mejor modelo para books\n",
      "\tAdaptando dominio\n",
      "4/4 dominios adaptados\n"
     ]
    }
   ],
   "source": [
    "#diccionario para mantener los dominios adaptados\n",
    "adapted = {}\n",
    "\n",
    "i = 0\n",
    "for domain in domains:\n",
    "    best_pca_path = os.path.join(models_path, tipo, \"%s_%s.pkl\" % (dataset_name, domain))\n",
    "    print best_pca_path\n",
    "    \n",
    "    if os.path.exists(best_pca_path):\n",
    "        print \"Cargando mejor modelo para %s\" % domain\n",
    "        pca_model = joblib.load(best_pca_path)\n",
    "        \n",
    "        print \"\\tAdaptando dominio\"\n",
    "        X_tr = np.asarray(labeled[domain]['X_tr'].todense())\n",
    "        X_ts = np.asarray(labeled[domain]['X_ts'].todense())\n",
    "        \n",
    "        \n",
    "        tr_reps = pca_model.transform(X_tr)\n",
    "        ts_reps = pca_model.transform(X_ts)\n",
    "\n",
    "        adapted[domain] = {\n",
    "            'X_tr': tr_reps,\n",
    "        }\n",
    "        \n",
    "        i = i+1\n",
    "    else:\n",
    "        print \"\\tGenerar mejor modelo para %s\" % domain\n",
    "        \n",
    "print \"%d/%d dominios adaptados\" % (i, len(domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 2 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 3 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 4 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 5 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 6 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 7 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 8 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 9 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 10 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 11 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 12 de 12\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "\n",
      "Pruebas completadas\n",
      "CPU times: user 48.6 s, sys: 1.1 s, total: 49.7 s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=0\n",
    "# por cada par posible para adaptar\n",
    "for src in domains:\n",
    "    best_pca_path = os.path.join(models_path, tipo, \"%s_%s.pkl\" % (dataset_name, src))\n",
    "    adapter = joblib.load(best_pca_path)\n",
    "    \n",
    "    for tgt in domains:\n",
    "        if src is not tgt:\n",
    "            print \"Tarea %d de 12\" % (i+1)\n",
    "            \n",
    "            #baseline in-domain error\n",
    "            #e_b(T,T)\n",
    "            #entrenado en dominio tgt y probado en dominio tgt\n",
    "            X_tr = np.asarray(labeled[tgt]['X_tr'].todense())\n",
    "            y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[tgt]['X_ts'].todense())\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            # se crean las rutas para cargar o crear los modelos\n",
    "            #model_name = \"%s_%s_%s.pkl\" % (tipo,src, tgt)\n",
    "            model_name = \"indomain_%s.pkl\" % (tgt)\n",
    "            model_path = os.path.join(models_path, dataset_name, model_name)\n",
    "            \n",
    "            \n",
    "            #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "            #svc = get_best_score(X_tr, y_tr)\n",
    "            svc = load_best_score(model_path, X_tr, y_tr)\n",
    "            b_error = 1-svc.score(X_ts, y_ts)\n",
    "            \n",
    "            #transfer error\n",
    "            #entrenado en dominio src y probado en dominio tgt adaptados\n",
    "            X_tr_a = adapted[src]['X_tr']\n",
    "            y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts_a = adapter.transform(X_ts)\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            print \"Entrenando clasificador adaptado.\"\n",
    "            svc_a = get_best_score(X_tr_a, y_tr, clasifier='SVC', n_jobs=4)\n",
    "            #svc_a = SVC().fit(X_tr_a, y_tr)\n",
    "            \n",
    "            t_error = 1-svc_a.score(X_ts_a, y_ts)\n",
    "            \n",
    "            # transfer loss t\n",
    "            # t_error - b_error\n",
    "            t_loss = t_error - b_error\n",
    "            \n",
    "            tarea = src[0]+'->'+tgt[0]\n",
    "            df.loc[i] = ['PCA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "            \n",
    "            i+=1\n",
    "\n",
    "print \"\\nPruebas completadas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;d</td>\n",
       "      <td>electronics</td>\n",
       "      <td>dvd</td>\n",
       "      <td>23.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;k</td>\n",
       "      <td>electronics</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>17.50</td>\n",
       "      <td>22.25</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA</td>\n",
       "      <td>e-&gt;b</td>\n",
       "      <td>electronics</td>\n",
       "      <td>books</td>\n",
       "      <td>21.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;e</td>\n",
       "      <td>dvd</td>\n",
       "      <td>electronics</td>\n",
       "      <td>20.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>14.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;k</td>\n",
       "      <td>dvd</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>17.50</td>\n",
       "      <td>25.00</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA</td>\n",
       "      <td>d-&gt;b</td>\n",
       "      <td>dvd</td>\n",
       "      <td>books</td>\n",
       "      <td>21.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;e</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>electronics</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;d</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>dvd</td>\n",
       "      <td>23.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCA</td>\n",
       "      <td>k-&gt;b</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>books</td>\n",
       "      <td>21.25</td>\n",
       "      <td>35.00</td>\n",
       "      <td>13.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;e</td>\n",
       "      <td>books</td>\n",
       "      <td>electronics</td>\n",
       "      <td>20.00</td>\n",
       "      <td>29.25</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;d</td>\n",
       "      <td>books</td>\n",
       "      <td>dvd</td>\n",
       "      <td>23.00</td>\n",
       "      <td>27.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PCA</td>\n",
       "      <td>b-&gt;k</td>\n",
       "      <td>books</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>17.50</td>\n",
       "      <td>28.00</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptacion Tarea       Fuente     Objetivo  Baseline error  Transfer error  \\\n",
       "0         PCA  e->d  electronics          dvd           23.00           34.50   \n",
       "1         PCA  e->k  electronics      kitchen           17.50           22.25   \n",
       "2         PCA  e->b  electronics        books           21.25           35.25   \n",
       "3         PCA  d->e          dvd  electronics           20.00           34.50   \n",
       "4         PCA  d->k          dvd      kitchen           17.50           25.00   \n",
       "5         PCA  d->b          dvd        books           21.25           31.50   \n",
       "6         PCA  k->e      kitchen  electronics           20.00           20.00   \n",
       "7         PCA  k->d      kitchen          dvd           23.00           30.00   \n",
       "8         PCA  k->b      kitchen        books           21.25           35.00   \n",
       "9         PCA  b->e        books  electronics           20.00           29.25   \n",
       "10        PCA  b->d        books          dvd           23.00           27.50   \n",
       "11        PCA  b->k        books      kitchen           17.50           28.00   \n",
       "\n",
       "    Transfer loss  \n",
       "0           11.50  \n",
       "1            4.75  \n",
       "2           14.00  \n",
       "3           14.50  \n",
       "4            7.50  \n",
       "5           10.25  \n",
       "6            0.00  \n",
       "7            7.00  \n",
       "8           13.75  \n",
       "9            9.25  \n",
       "10           4.50  \n",
       "11          10.50  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/pca/amazon.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path = os.path.join(scores_path, tipo, \"%s_%d.csv\" % (dataset_name, dims))\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
