{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#adaptacion\n",
    "from utils.adaptacion import create_SDA\n",
    "\n",
    "# clasificadores\n",
    "from sklearn.svm import SVC\n",
    "from utils.clasificacion import *\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#variables para guardar los resultados\n",
    "tipo = pruebas[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dataset de Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print pruebas\n",
    "print datasets[1]\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargando dataset de Twitter\n",
    "dataset_path = os.path.join(data_path, datasets[1]+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se obtienen todos los valores X disponibles para realizar adaptacion\n",
    "X = dataset_object.get_all_X()\n",
    "X = np.asarray(X)\n",
    "\n",
    "print \"Todos los datos disponibles obtenidos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder, encoder = create_SDA(784, [128, 64, 32, 16, 8])\n",
    "print \"Creando Stacked Autoencoder...\"\n",
    "autoencoder, encoder = create_SDA(dims, [1000])\n",
    "print \"Stacked Autoencoder creado.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:, :dims]\n",
    "\n",
    "#TODO: resolver lo de validation data\n",
    "autoencoder.fit(X_train, X_train,\n",
    "               epochs=50,\n",
    "               batch_size=256,\n",
    "               shuffle=True,\n",
    "               validation_data=(X_train, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diccionario para mantener los dominios adaptados\n",
    "adapted = {}\n",
    "\n",
    "for domain in domains:\n",
    "    print \"Adaptando %s\" % domain\n",
    "    X_tr = np.asarray(labeled[domain]['X_tr'][:, :dims].todense())\n",
    "    X_ts = np.asarray(labeled[domain]['X_ts'][:, :dims].todense())\n",
    "    \n",
    "    tr_reps = encoder.predict(X_tr[:, :dims])\n",
    "    ts_reps = encoder.predict(X_ts[:, :dims])\n",
    "    \n",
    "    adapted[domain] = {\n",
    "        'X_tr': tr_reps,\n",
    "        'X_ts': ts_reps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i = 0\n",
    "# por cada par posible para adaptar\n",
    "for src in domains:\n",
    "    for tgt in domains:\n",
    "        if src is not tgt:\n",
    "            print \"Tarea %d de 2\" % (i+1)\n",
    "            \n",
    "            #baseline in-domain error\n",
    "            #e_b(T,T)\n",
    "            #entrenado en dominio tgt y probado en dominio tgt\n",
    "            X_tr = np.asarray(labeled[tgt]['X_tr'][:, :dims].todense())\n",
    "            y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[tgt]['X_ts'][:, :dims].todense())\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            # se crean las rutas para cargar o crear los modelos\n",
    "            #model_name = \"%s_%s_%s.pkl\" % (tipo,src, tgt)\n",
    "            model_name = \"indomain_%s.pkl\" % (tgt)\n",
    "            model_path = os.path.join(models_path, datasets[1], model_name)\n",
    "            \n",
    "            #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "            svc = load_best_score(model_path, X_tr, y_tr)\n",
    "            b_error = 1-svc.score(X_ts, y_ts)\n",
    "            \n",
    "            #transfer error\n",
    "            #entrenado en dominio src y probado en dominio tgt adaptados\n",
    "            X_tr_a = adapted[src]['X_tr']\n",
    "            y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts_a = adapted[tgt]['X_ts']\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            svc_a = SVC(kernel='linear')\n",
    "            svc_a = svc_a.fit(X_tr_a, y_tr)\n",
    "            \n",
    "            t_error = 1-svc_a.score(X_ts_a, y_ts)\n",
    "            \n",
    "            # transfer loss t\n",
    "            # t_error - b_error\n",
    "            t_loss = t_error - b_error\n",
    "            \n",
    "            tarea = src[0]+'->'+tgt[0]\n",
    "            df.loc[i] = ['SDA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "            i+=1\n",
    "\n",
    "print \"Pruebas completadas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores_path = os.path.join(scores_path, tipo, datasets[1]+\".csv\")\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
