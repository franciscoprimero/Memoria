{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#adaptacion\n",
    "from utils.adaptacion import msda_theano_pseudo_grid_search \n",
    "\n",
    "#otros\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "tipo = pruebas[1]\n",
    "dataset_name = datasets[0]\n",
    "dims = dimensions[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con el dataset Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msda\n",
      "amazon\n",
      "3000\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print dims\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Amazon\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27677, 3000)\n",
      "Todos los datos disponibles obtenidos\n"
     ]
    }
   ],
   "source": [
    "# se obtienen todos los valores X disponibles para realizar adaptacion\n",
    "X = dataset_object.get_all_X()\n",
    "X = np.asarray(X)\n",
    "\n",
    "print X.shape\n",
    "\n",
    "print \"Todos los datos disponibles obtenidos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptación\n",
    "\n",
    "\n",
    "## Creación de modelos de adaptación.\n",
    "\n",
    "Para cada dominio se entrenan distintos modelos según los parámetros enviados.\n",
    "\n",
    "Cada modelo es guardado en la ruta: models/amazon/msda/me1\\_[dominio\\_objetivo]_[numero_de_modelo].pkl\n",
    "\n",
    "Todas las rutas son guardadas en una lista, la cual es almacenada en: models/amazon/msda/me1_models_paths.pkl\n",
    "\n",
    "```python\n",
    "paths_list = [ruta1, ..., ruta_n]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando modelos de adaptacion...\n",
      "\tpr: 0.300 - l: 1\n",
      "\tEntrenando capa  1\n",
      "\tEntrenado en 2.59m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_0.pkl\n",
      "\tpr: 0.300 - l: 3\n",
      "\tEntrenando capa  1\n",
      "\tEntrenando capa  2\n",
      "\tEntrenando capa  3\n",
      "\tEntrenado en 7.18m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_1.pkl\n",
      "\tpr: 0.300 - l: 5\n",
      "\tEntrenando capa  1\n",
      "\tEntrenando capa  2\n",
      "\tEntrenando capa  3\n",
      "\tEntrenando capa  4\n",
      "\tEntrenando capa  5\n",
      "\tEntrenado en 12.01m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_2.pkl\n",
      "\tpr: 0.500 - l: 1\n",
      "\tEntrenando capa  1\n",
      "\tEntrenado en 2.39m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_3.pkl\n",
      "\tpr: 0.500 - l: 3\n",
      "\tEntrenando capa  1\n",
      "\tEntrenando capa  2\n",
      "\tEntrenando capa  3\n",
      "\tEntrenado en 7.15m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_4.pkl\n",
      "\tpr: 0.500 - l: 5\n",
      "\tEntrenando capa  1\n",
      "\tEntrenando capa  2\n",
      "\tEntrenando capa  3\n",
      "\tEntrenando capa  4\n",
      "\tEntrenando capa  5\n",
      "\tEntrenado en 12.22m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_5.pkl\n",
      "\tpr: 0.800 - l: 1\n",
      "\tEntrenando capa  1\n",
      "\tEntrenado en 2.42m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_6.pkl\n",
      "\tpr: 0.800 - l: 3\n",
      "\tEntrenando capa  1\n",
      "\tEntrenando capa  2\n",
      "\tEntrenando capa  3\n",
      "\tEntrenado en 7.19m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_7.pkl\n",
      "\tpr: 0.800 - l: 5\n",
      "\tEntrenando capa  1\n",
      "\tEntrenando capa  2\n",
      "\tEntrenando capa  3\n",
      "\tEntrenando capa  4\n",
      "\tEntrenando capa  5\n",
      "\tEntrenado en 11.90m\n",
      "\n",
      "\tGuardando modelo en models/amazon/msda/me1_8.pkl\n",
      "\n",
      "Creacion de modelos terminada\n",
      "Guardando rutas en models/amazon/msda/me1_models_paths.pkl\n",
      "Rutas cargadas en la variable 'paths_list'\n"
     ]
    }
   ],
   "source": [
    "models_paths = os.path.join(models_path, dataset_name, tipo, \"me1_models_paths.pkl\")\n",
    "paths_list = []\n",
    "\n",
    "# si existe el archivo con las rutas\n",
    "# se carga la lista con las rutas\n",
    "if os.path.exists(models_paths):\n",
    "    print \"Cargando rutas de modelos adaptados.\"\n",
    "    paths_list = joblib.load(models_paths)\n",
    "    print \"Rutas cargadas en la variable 'paths_list'\"\n",
    "# si no\n",
    "# se entrenan los modelos y se obtiene la lista con rutas\n",
    "else:\n",
    "    #se establecen los parametros para los modelos\n",
    "    parametros = {\n",
    "        'noises': [0.3, 0.5, 0.8],\n",
    "        'layers': [1, 3, 5]\n",
    "    }\n",
    "\n",
    "    print \"Creando modelos de adaptacion...\"\n",
    "    \n",
    "    folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "    prefix = \"me1_\"\n",
    "        \n",
    "    paths_list = msda_theano_pseudo_grid_search(X, parametros, folder_path, prefix)\n",
    "\n",
    "    print \"\\nCreacion de modelos terminada\\nGuardando rutas en %s\" % models_paths\n",
    "    joblib.dump(paths_list, models_paths)\n",
    "    print \"Rutas cargadas en la variable 'paths_list'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos almacenados en:\n",
      "\tmodels/amazon/msda/me1_0.pkl\n",
      "\tmodels/amazon/msda/me1_1.pkl\n",
      "\tmodels/amazon/msda/me1_2.pkl\n",
      "\tmodels/amazon/msda/me1_3.pkl\n",
      "\tmodels/amazon/msda/me1_4.pkl\n",
      "\tmodels/amazon/msda/me1_5.pkl\n",
      "\tmodels/amazon/msda/me1_6.pkl\n",
      "\tmodels/amazon/msda/me1_7.pkl\n",
      "\tmodels/amazon/msda/me1_8.pkl\n"
     ]
    }
   ],
   "source": [
    "print \"Modelos almacenados en:\"\n",
    "for ruta in paths_list:\n",
    "    print \"\\t\", ruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda del mejor modelo por dominio\n",
    "\n",
    "Por cada dominio se busca el mejor modelo de adaptación.\n",
    "\n",
    "Esto se obtiene adaptando los datos de entrenamiento de cada dominio por cada modelo creado y realizando Grid-Search y Cross-Validation con estos datos.\n",
    "\n",
    "El modelo que logre un mejor valor de Cross-Validation es considerado el mejor modelo para adaptar y queda guardado en un diccionario de la forma:\n",
    "\n",
    "```python\n",
    "best_models = {\n",
    "    [dominio_1] = ruta,\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    [dominio_n] = ruta,\n",
    "}\n",
    "```\n",
    "\n",
    "Este diccionario queda almacenado en la ruta:\n",
    "    models/amazon/msda/me1_best_models.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo mejores modelos...\n",
      "electronics\n",
      "\t1) l=1, pr=0.300  score: 0.9049\n",
      "\t2) l=3, pr=0.300 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " score: 0.8997\n",
      "\t3) l=5, pr=0.300  score: 0.8927\n",
      "\t4) l=1, pr=0.500  score: 0.9059\n",
      "\t5) l=3, pr=0.500  score: 0.8812\n",
      "\t6) l=5, pr=0.500  score: 0.8030\n",
      "\t7) l=1, pr=0.800  score: 0.9104\n",
      "\t8) l=3, pr=0.800  score: 0.8008\n",
      "\t9) l=5, pr=0.800  score: 0.7720\n",
      "Mejor modelo: l=1, pr=0.800\n",
      "dvd\n",
      "\t1) l=1, pr=0.300  score: 0.8484\n",
      "\t2) l=3, pr=0.300  score: 0.8453\n",
      "\t3) l=5, pr=0.300  score: 0.8142\n",
      "\t4) l=1, pr=0.500  score: 0.8473\n",
      "\t5) l=3, pr=0.500  score: 0.7886\n",
      "\t6) l=5, pr=0.500  score: 0.7365\n",
      "\t7) l=1, pr=0.800  score: 0.8611\n",
      "\t8) l=3, pr=0.800  score: 0.7473\n",
      "\t9) l=5, pr=0.800  score: 0.6933\n",
      "Mejor modelo: l=1, pr=0.800\n",
      "kitchen\n",
      "\t1) l=1, pr=0.300  score: 0.9207\n",
      "\t2) l=3, pr=0.300  score: 0.9115\n",
      "\t3) l=5, pr=0.300  score: 0.8916\n",
      "\t4) l=1, pr=0.500  score: 0.9198\n",
      "\t5) l=3, pr=0.500  score: 0.8768\n",
      "\t6) l=5, pr=0.500  score: 0.8130\n",
      "\t7) l=1, pr=0.800  score: 0.9205\n",
      "\t8) l=3, pr=0.800  score: 0.8287\n",
      "\t9) l=5, pr=0.800  score: 0.8045\n",
      "Mejor modelo: l=1, pr=0.300\n",
      "books\n",
      "\t1) l=1, pr=0.300  score: 0.8411\n",
      "\t2) l=3, pr=0.300  score: 0.8490\n",
      "\t3) l=5, pr=0.300  score: 0.8378\n",
      "\t4) l=1, pr=0.500  score: 0.8407\n",
      "\t5) l=3, pr=0.500  score: 0.8338\n",
      "\t6) l=5, pr=0.500  score: 0.7577\n",
      "\t7) l=1, pr=0.800  score: 0.8470\n",
      "\t8) l=3, pr=0.800  score: 0.7660\n",
      "\t9) l=5, pr=0.800  score: 0.7363\n",
      "Mejor modelo: l=3, pr=0.300\n",
      "Rutas guardadas en  models/amazon/msda/me1_best_models.pkl\n"
     ]
    }
   ],
   "source": [
    "best_models_paths = os.path.join(models_path, dataset_name, tipo, \"me1_best_models.pkl\")\n",
    "best_models = {}\n",
    "\n",
    "if os.path.exists(best_models_paths):\n",
    "    print \"Cargando rutas de los mejores modelos...\"\n",
    "    best_models = joblib.load(best_models_paths)\n",
    "    print \"Rutas cargadas\"  \n",
    "else:\n",
    "    print \"Obteniendo mejores modelos...\"\n",
    "    for domain in domains:\n",
    "        print domain\n",
    "        i = 1\n",
    "        best_score = 0\n",
    "        best_path = None\n",
    "        best_model = None\n",
    "        \n",
    "        for msda_model_path in paths_list:\n",
    "            \n",
    "            msda_model = joblib.load(msda_model_path)\n",
    "            theano_model = msda_model['model']\n",
    "            pr = msda_model['pr']\n",
    "            n_layers = msda_model['l']\n",
    "\n",
    "            print \"\\t%d) l=%d, pr=%.3f \" % (i, msda_model['l'], msda_model['pr']),\n",
    "\n",
    "            # se obtienen los datos del dominio\n",
    "            X_tr = np.asarray(labeled[domain]['X_tr'].todense())\n",
    "            y_tr = np.asarray(labeled[domain]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "            # se adaptan los datos\n",
    "            X_deep = theano_model.predict(X_tr)\n",
    "\n",
    "            # se obtiene el mejor score con GridSearch\n",
    "            new_clf = get_best_score(X_deep, y_tr, classifier='SVC', n_jobs=4)\n",
    "            new_score = new_clf.best_score_\n",
    "            print \"score: %.4f\" % new_score\n",
    "            # se guarda si es el mejor para el modelo\n",
    "            if new_score > best_score:\n",
    "                best_score = new_score\n",
    "                best_path = msda_model_path\n",
    "                best_model = msda_model\n",
    "            i = i+1\n",
    "\n",
    "        #se guarda el mejor modelo para este dominio\n",
    "        print \"Mejor modelo: l=%d, pr=%.3f\" % (best_model['l'], best_model['pr'])\n",
    "        best_models[domain] = best_path\n",
    "        \n",
    "    \n",
    "    # se guarda el diccionario con las mejores rutas\n",
    "    joblib.dump(best_models, best_models_paths)\n",
    "    print \"Rutas guardadas en \", best_models_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvd - models/amazon/msda/me1_6.pkl\n",
      "electronics - models/amazon/msda/me1_6.pkl\n",
      "books - models/amazon/msda/me1_1.pkl\n",
      "kitchen - models/amazon/msda/me1_0.pkl\n"
     ]
    }
   ],
   "source": [
    "for dominio, ruta in best_models.items():\n",
    "    print \"%s - %s\" % (dominio, ruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando mejor modelo para electronics\n",
      "\tAdaptando dominio\n",
      "Cargando mejor modelo para dvd\n",
      "\tAdaptando dominio\n",
      "Cargando mejor modelo para kitchen\n",
      "\tAdaptando dominio\n",
      "Cargando mejor modelo para books\n",
      "\tAdaptando dominio\n",
      "4/4 dominios adaptados\n"
     ]
    }
   ],
   "source": [
    "#diccionario para mantener los dominios adaptados\n",
    "adapted = {}\n",
    "\n",
    "i = 0\n",
    "for domain in domains:\n",
    "    best_model_path = best_models[domain]\n",
    "    \n",
    "    if os.path.exists(best_model_path):\n",
    "        print \"Cargando mejor modelo para %s\" % domain\n",
    "        msda_model = joblib.load(best_model_path)\n",
    "        theano_model = msda_model['model']\n",
    "        \n",
    "        print \"\\tAdaptando dominio\"\n",
    "        X_tr = np.asarray(labeled[domain]['X_tr'].todense())\n",
    "\n",
    "        tr_reps = theano_model.predict(X_tr)\n",
    "\n",
    "        adapted[domain] = {\n",
    "            'X_tr': tr_reps\n",
    "        }\n",
    "        \n",
    "        i = i+1\n",
    "    else:\n",
    "        print \"\\tGenerar mejor modelo para %s\" % domain\n",
    "        \n",
    "print \"%d/%d dominios adaptados\" % (i, len(domains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 2 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 3 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 4 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 5 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 6 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 7 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 8 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 9 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 10 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 11 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 12 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "\n",
      "Pruebas completadas\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=1\n",
    "tareas = len(domains)*(len(domains)-1)\n",
    "\n",
    "# por cada par posible para adaptar\n",
    "for src in domains:\n",
    "    #se carga el mejor modelo para el dominio fuente\n",
    "    ruta = best_models[src]\n",
    "    modelo = joblib.load(ruta)\n",
    "    msda_adapter = modelo['model']\n",
    "    \n",
    "    for tgt in domains:\n",
    "        if src is not tgt:\n",
    "            print \"Tarea %d de %d\" % (i, tareas)\n",
    "            \n",
    "            #baseline in-domain error\n",
    "            #e_b(T,T)\n",
    "            #entrenado en dominio tgt y probado en dominio tgt\n",
    "            X_tr = np.asarray(labeled[tgt]['X_tr'].todense())\n",
    "            y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[tgt]['X_ts'].todense())\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            # se crean las rutas para cargar o crear los modelos\n",
    "            model_name = \"%s.pkl\" % (tgt)\n",
    "            model_path = os.path.join(models_path, dataset_name, \"indomain\", model_name)\n",
    "            \n",
    "            \n",
    "            #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "            svc = load_best_score(model_path, X_tr, y_tr)\n",
    "            b_error = 1-svc.score(X_ts, y_ts)\n",
    "            \n",
    "            \n",
    "            #############\n",
    "            #### mSDA ###\n",
    "            #############\n",
    "            print \"Adaptando dominios...\"\n",
    "            \n",
    "            #entrenado en dominio src y probado en dominio tgt adaptados\n",
    "            X_tr_a = adapted[src]['X_tr']\n",
    "            y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts_a = msda_adapter.predict(X_ts)\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            # se calcula el transfer error\n",
    "            svc_a = get_best_score(X_tr_a, y_tr, classifier='SVC', n_jobs=4)\n",
    "            t_error = 1-svc_a.score(X_ts_a, y_ts)\n",
    "            \n",
    "            # transfer loss t\n",
    "            # t_error - b_error\n",
    "            t_loss = t_error - b_error\n",
    "            \n",
    "            tarea = src[0]+'->'+tgt[0]\n",
    "            df.loc[i] = ['mSDA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "            \n",
    "            i+=1\n",
    "    \n",
    "print \"\\nPruebas completadas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>e-&gt;d</td>\n",
       "      <td>electronics</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>26.238156</td>\n",
       "      <td>10.475262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>e-&gt;k</td>\n",
       "      <td>electronics</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>9.547739</td>\n",
       "      <td>0.960024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>e-&gt;b</td>\n",
       "      <td>electronics</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>26.305658</td>\n",
       "      <td>11.147779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>d-&gt;e</td>\n",
       "      <td>dvd</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>23.378084</td>\n",
       "      <td>12.250306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>d-&gt;k</td>\n",
       "      <td>dvd</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>17.105428</td>\n",
       "      <td>8.517713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>d-&gt;b</td>\n",
       "      <td>dvd</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>22.785570</td>\n",
       "      <td>7.627691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>k-&gt;e</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>12.337808</td>\n",
       "      <td>1.210030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>k-&gt;d</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>28.085702</td>\n",
       "      <td>12.322808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>k-&gt;b</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>30.045751</td>\n",
       "      <td>14.887872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>b-&gt;e</td>\n",
       "      <td>books</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>23.728093</td>\n",
       "      <td>12.600315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>b-&gt;d</td>\n",
       "      <td>books</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>20.268007</td>\n",
       "      <td>4.505113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mSDA</td>\n",
       "      <td>b-&gt;k</td>\n",
       "      <td>books</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>20.638016</td>\n",
       "      <td>12.050301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptacion Tarea       Fuente     Objetivo  Baseline error  Transfer error  \\\n",
       "1        mSDA  e->d  electronics          dvd       15.762894       26.238156   \n",
       "2        mSDA  e->k  electronics      kitchen        8.587715        9.547739   \n",
       "3        mSDA  e->b  electronics        books       15.157879       26.305658   \n",
       "4        mSDA  d->e          dvd  electronics       11.127778       23.378084   \n",
       "5        mSDA  d->k          dvd      kitchen        8.587715       17.105428   \n",
       "6        mSDA  d->b          dvd        books       15.157879       22.785570   \n",
       "7        mSDA  k->e      kitchen  electronics       11.127778       12.337808   \n",
       "8        mSDA  k->d      kitchen          dvd       15.762894       28.085702   \n",
       "9        mSDA  k->b      kitchen        books       15.157879       30.045751   \n",
       "10       mSDA  b->e        books  electronics       11.127778       23.728093   \n",
       "11       mSDA  b->d        books          dvd       15.762894       20.268007   \n",
       "12       mSDA  b->k        books      kitchen        8.587715       20.638016   \n",
       "\n",
       "    Transfer loss  \n",
       "1       10.475262  \n",
       "2        0.960024  \n",
       "3       11.147779  \n",
       "4       12.250306  \n",
       "5        8.517713  \n",
       "6        7.627691  \n",
       "7        1.210030  \n",
       "8       12.322808  \n",
       "9       14.887872  \n",
       "10      12.600315  \n",
       "11       4.505113  \n",
       "12      12.050301  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/amazon/msda/me1_3000.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path = os.path.join(scores_path,dataset_name, tipo, \"me1_%d.csv\" % (dims))\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
