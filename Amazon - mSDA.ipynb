{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#adaptacion\n",
    "from mSDA import msda\n",
    "from utils.adaptacion import *\n",
    "\n",
    "#otros\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tipo = pruebas[1]\n",
    "dataset_name = datasets[0]\n",
    "dims = dimensions[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con el dataset Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msda\n",
      "amazon\n",
      "5000\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print dims\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Amazon\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "unlabeled = dataset_object.unlabeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los datos disponibles obtenidos\n"
     ]
    }
   ],
   "source": [
    "# se obtienen todos los valores X disponibles para realizar adaptacion\n",
    "X = dataset_object.get_all_X()\n",
    "X = np.asarray(X)\n",
    "\n",
    "print \"Todos los datos disponibles obtenidos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "saved_paths = [ruta_1,...,ruta_n]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando modelos de adaptacion...\n",
      "pr: 0.300 - l: 1\n"
     ]
    }
   ],
   "source": [
    "msda_paths = os.path.join(models_path, tipo, \"%s_paths.pkl\" % dataset_name)\n",
    "\n",
    "if os.path.exists(msda_paths):\n",
    "    print \"Cargando rutas de modelos adaptados.\"\n",
    "    saved_paths = joblib.load(msda_paths)\n",
    "else:\n",
    "    print \"Creando modelos de adaptacion...\"\n",
    "\n",
    "    noises = [0.3, 0.5, 0.8]\n",
    "    layers_sizes = [1, 3, 5]\n",
    "\n",
    "    parametros = {\n",
    "        'noises': noises,\n",
    "        'layers': layers_sizes\n",
    "    }\n",
    "\n",
    "\n",
    "    saved_paths = msda_pseudo_grid_search(X, parametros, models_path, tipo, dataset_name)\n",
    "\n",
    "    print \"Modelos creados.\\n\"\n",
    "    \n",
    "    save_adapted_model(saved_paths, msda_paths)\n",
    "    print \"Guardando rutas en %s\" % msda_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "domain_msda_paths = [ruta_1,...,ruta_n]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_msda_paths = os.path.join(models_path, tipo, \"best_%s_paths.pkl\" % dataset_name )\n",
    "if os.path.exists(best_msda_paths):\n",
    "    #se cargan las rutas de los modelos guardados\n",
    "    domain_msda_paths = joblib.load(best_msda_paths)   \n",
    "else:\n",
    "    domain_msda_paths = []\n",
    "    #se obtienen los mejores modelos \n",
    "    for domain in domains:\n",
    "        print \"Obteniendo mejor clasificador para %s\" % domain\n",
    "        i = 1\n",
    "\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        for msda_model_path in saved_paths:\n",
    "            #print \"Modelo %d de %d\" % (i, len(saved_paths))\n",
    "\n",
    "\n",
    "            msda_model = joblib.load(msda_model_path)\n",
    "            mapping = msda_model['mapping']\n",
    "            pr = msda_model['pr']\n",
    "            n_layers = msda_model['l']\n",
    "\n",
    "            print \"l=%d, pr=%.3f \" % (msda_model['l'], msda_model['pr']),\n",
    "\n",
    "            # se obtienen los datos del dominio\n",
    "            X_tr = np.asarray(labeled[domain]['X_tr'][:, :dims].todense())\n",
    "            y_tr = np.asarray(labeled[domain]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "            # se adaptan los datos\n",
    "            X_deep = msda.mSDA(X_tr, pr, n_layers, mapping)[1][:][:][-1]\n",
    "\n",
    "            # se obtiene el mejor score con GridSearch\n",
    "            new_clf = get_best_score(X_deep, y_tr, clasifier='SVC')\n",
    "            new_score = new_clf.best_score_\n",
    "            print \"score: %.4f\" % new_score\n",
    "            # se guarda si es el mejor para el modelo\n",
    "            if new_score > best_score:\n",
    "                best_score = new_score\n",
    "                best_model = msda_model\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "        #se guarda el mejor modelo para este dominio\n",
    "        print \"Mejor modelo: l=%d, pr=%.3f\" % (best_model['l'], best_model['pr'])\n",
    "        best_msda_path = os.path.join(models_path, tipo, \"%s_%s.pkl\" % (dataset_name, domain))\n",
    "        print \"Guardando en %s\" % best_msda_path\n",
    "        joblib.dump(best_model, best_msda_path)\n",
    "        \n",
    "        domain_msda_paths.append(best_msda_path)\n",
    "    \n",
    "    print \"Guardando rutas en %s\" % best_msda_paths\n",
    "    joblib.dump(domain_msda_paths, best_msda_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_msda_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#diccionario para mantener los dominios adaptados\n",
    "adapted = {}\n",
    "\n",
    "i = 0\n",
    "for domain in domains:\n",
    "    best_msda_path = os.path.join(models_path, tipo, \"%s_%s.pkl\" % (dataset_name, domain))\n",
    "    \n",
    "    if os.path.exists(best_msda_path):\n",
    "        print \"Cargando mejor modelo para %s\" % domain\n",
    "        msda_model = joblib.load(best_msda_path)\n",
    "        mapping = msda_model['mapping']\n",
    "        \n",
    "        print \"Adaptando dominio\"\n",
    "        X_tr = np.asarray(labeled[domain]['X_tr'].todense())\n",
    "        X_ts = np.asarray(labeled[domain]['X_ts'].todense())\n",
    "        \n",
    "        \n",
    "        tr_reps = msda.mSDA(X_tr, pr, n_layers, mapping)[1][:][:][-1]\n",
    "        ts_reps = msda.mSDA(X_ts, pr, n_layers, mapping)[1][:][:][-1]\n",
    "\n",
    "        adapted[domain] = {\n",
    "            'X_tr': tr_reps,\n",
    "            'X_ts': ts_reps\n",
    "        }\n",
    "        \n",
    "        i = i+1\n",
    "    else:\n",
    "        print \"Generar mejor modelo para %s\" % domain\n",
    "        \n",
    "print \"%d/%d dominios adaptados\" % (i, len(domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=0\n",
    "# por cada par posible para adaptar\n",
    "for src in domains:\n",
    "    for tgt in domains:\n",
    "        if src is not tgt:\n",
    "            print \"Tarea %d de 12\" % (i+1)\n",
    "            \n",
    "            #baseline in-domain error\n",
    "            #e_b(T,T)\n",
    "            #entrenado en dominio tgt y probado en dominio tgt\n",
    "            X_tr = np.asarray(labeled[tgt]['X_tr'][:, :dims].todense())\n",
    "            y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[tgt]['X_ts'][:, :dims].todense())\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            # se crean las rutas para cargar o crear los modelos\n",
    "            #model_name = \"%s_%s_%s.pkl\" % (tipo,src, tgt)\n",
    "            model_name = \"indomain_%s.pkl\" % (tgt)\n",
    "            model_path = os.path.join(models_path, dataset_name, model_name)\n",
    "            \n",
    "            \n",
    "            #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "            #svc = get_best_score(X_tr, y_tr)\n",
    "            svc = load_best_score(model_path, X_tr, y_tr)\n",
    "            b_error = 1-svc.score(X_ts, y_ts)\n",
    "            \n",
    "            \n",
    "            #transfer error\n",
    "            #entrenado en dominio src y probado en dominio tgt adaptados\n",
    "            X_tr_a = adapted[src]['X_tr']\n",
    "            y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts_a = adapted[tgt]['X_ts']\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            print \"Entrenando clasificador adaptado.\"\n",
    "            svc_a = get_best_score(X_tr_a, y_tr)\n",
    "            \n",
    "            t_error = 1-svc_a.score(X_ts_a, y_ts)\n",
    "            \n",
    "            # transfer loss t\n",
    "            # t_error - b_error\n",
    "            t_loss = t_error - b_error\n",
    "            \n",
    "            tarea = src[0]+'->'+tgt[0]\n",
    "            df.loc[i] = ['mSDA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "            \n",
    "            i+=1\n",
    "    \n",
    "print \"Pruebas completadas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_scores_path = os.path.join(scores_path, tipo, dataset_name+\".csv\")\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
