{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaptacion\n",
    "from utils.adaptacion import gfk_train_all, transform_gfk, gfk_compute_accuracy\n",
    "\n",
    "#clasificadores\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#otros\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import itertools\n",
    "\n",
    "#variables para guardar los resultados\n",
    "tipo = pruebas[2]\n",
    "dataset_name = datasets[0]\n",
    "dims = dimensions[dataset_name]\n",
    "marco = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con el dataset Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gfk\n",
      "amazon\n",
      "3000\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print dims\n",
    "print data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Amazon\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "unlabeled = dataset_object.unlabeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptación\n",
    "\n",
    "## Creación de modelos de adaptación.\n",
    "\n",
    "Para cada dominio se entrenan distintos modelos según los parámetros enviados.\n",
    "\n",
    "Cada modelo es guardado en la ruta: models/amazon/gfk/me1\\_[dominio\\_objetivo]_[numero_de_modelo].pkl\n",
    "\n",
    "Todas las rutas son guardadas en un diccionario separado por dominios, en donde cada dominio contiene una lista con las rutas. El diccionario es almacenado en: models/amazon/gfk/me1_models_paths.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21212, 3000)\n",
      "(6465, 3000)\n"
     ]
    }
   ],
   "source": [
    "def get_source_target_train_data(target_domain, dataset_object):\n",
    "    X = None\n",
    "    X_tgt = None\n",
    "    for domain in dataset_object.domains:\n",
    "        if target_domain == domain:\n",
    "            X_tgt = dataset_object.get_all_domain_X(target_domain)\n",
    "        else:\n",
    "            if X is None:\n",
    "                X = dataset_object.get_all_domain_X(domain)\n",
    "            else:\n",
    "                X_tmp = dataset_object.get_all_domain_X(domain)\n",
    "                X = np.concatenate([X, X_tmp])\n",
    "    \n",
    "    return X, X_tgt\n",
    "\n",
    "\n",
    "X, X_tgt = get_source_target_train_data('books', dataset_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando modelos de adaptacion...\n",
      "electronics\n",
      "\tEntrenando modelo 0\n",
      "\tGuardando modelo en models/amazon/gfk/me1_electronics_0.pkl\n",
      "\tEntrenando modelo 1\n",
      "\tGuardando modelo en models/amazon/gfk/me1_electronics_1.pkl\n",
      "\tEntrenando modelo 2\n",
      "\tGuardando modelo en models/amazon/gfk/me1_electronics_2.pkl\n",
      "\tEntrenando modelo 3\n",
      "\tGuardando modelo en models/amazon/gfk/me1_electronics_3.pkl\n",
      "\tEntrenando modelo 4\n",
      "\tGuardando modelo en models/amazon/gfk/me1_electronics_4.pkl\n",
      "\tEntrenando modelo 5\n",
      "\tGuardando modelo en models/amazon/gfk/me1_electronics_5.pkl\n",
      "dvd\n",
      "\tEntrenando modelo 0\n",
      "\tGuardando modelo en models/amazon/gfk/me1_dvd_0.pkl\n",
      "\tEntrenando modelo 1\n",
      "\tGuardando modelo en models/amazon/gfk/me1_dvd_1.pkl\n",
      "\tEntrenando modelo 2\n",
      "\tGuardando modelo en models/amazon/gfk/me1_dvd_2.pkl\n",
      "\tEntrenando modelo 3\n",
      "\tGuardando modelo en models/amazon/gfk/me1_dvd_3.pkl\n",
      "\tEntrenando modelo 4\n",
      "\tGuardando modelo en models/amazon/gfk/me1_dvd_4.pkl\n",
      "\tEntrenando modelo 5\n",
      "\tGuardando modelo en models/amazon/gfk/me1_dvd_5.pkl\n",
      "kitchen\n",
      "\tEntrenando modelo 0\n",
      "\tGuardando modelo en models/amazon/gfk/me1_kitchen_0.pkl\n",
      "\tEntrenando modelo 1\n",
      "\tGuardando modelo en models/amazon/gfk/me1_kitchen_1.pkl\n",
      "\tEntrenando modelo 2\n",
      "\tGuardando modelo en models/amazon/gfk/me1_kitchen_2.pkl\n",
      "\tEntrenando modelo 3\n",
      "\tGuardando modelo en models/amazon/gfk/me1_kitchen_3.pkl\n",
      "\tEntrenando modelo 4\n",
      "\tGuardando modelo en models/amazon/gfk/me1_kitchen_4.pkl\n",
      "\tEntrenando modelo 5\n",
      "\tGuardando modelo en models/amazon/gfk/me1_kitchen_5.pkl\n",
      "books\n",
      "\tEntrenando modelo 0\n",
      "\tGuardando modelo en models/amazon/gfk/me1_books_0.pkl\n",
      "\tEntrenando modelo 1\n",
      "\tGuardando modelo en models/amazon/gfk/me1_books_1.pkl\n",
      "\tEntrenando modelo 2\n",
      "\tGuardando modelo en models/amazon/gfk/me1_books_2.pkl\n",
      "\tEntrenando modelo 3\n",
      "\tGuardando modelo en models/amazon/gfk/me1_books_3.pkl\n",
      "\tEntrenando modelo 4\n",
      "\tGuardando modelo en models/amazon/gfk/me1_books_4.pkl\n",
      "\tEntrenando modelo 5\n",
      "\tGuardando modelo en models/amazon/gfk/me1_books_5.pkl\n",
      "\n",
      "Creacion de modelos terminada\n",
      "Guardando rutas en models/amazon/gfk/me1_models_paths.pkl\n",
      "Rutas cargadas en la variable 'paths_dict'\n"
     ]
    }
   ],
   "source": [
    "models_paths = os.path.join(models_path, dataset_name, tipo, 'me1_models_paths.pkl')\n",
    "paths_dict = {}\n",
    "\n",
    "# si existe el archivo con las rutas\n",
    "# se carga la lista con las rutas\n",
    "if os.path.exists(models_paths):    \n",
    "    print \"Cargando rutas de modelos adaptados.\"\n",
    "    paths_dict = joblib.load(models_paths)\n",
    "    print \"Rutas cargadas en la variable 'paths_dict'\"\n",
    "\n",
    "# si no\n",
    "# se entrenan los modelos y se obtiene la lista con rutas\n",
    "else:\n",
    "    #se establecen los parametros para los modelos\n",
    "    parameters = {\n",
    "        'dims': [int(dims/4), int(dims/2)],\n",
    "        'n_subs': [10, 20, 50]\n",
    "    }\n",
    "    \n",
    "    print \"Creando modelos de adaptacion...\"\n",
    "    for target_domain in domains:\n",
    "        print target_domain\n",
    "        X , X_tgt = get_source_target_train_data(target_domain, dataset_object)\n",
    "        \n",
    "        folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "        prefix = \"me1_\"+target_domain+\"_\"\n",
    "        \n",
    "        new_paths = gfk_train_all(X, X_tgt, parameters, folder_path, prefix)\n",
    "    \n",
    "        paths_dict[target_domain] = new_paths\n",
    "    \n",
    "    print \"\\nCreacion de modelos terminada\\nGuardando rutas en %s\" % models_paths\n",
    "    joblib.dump(paths_dict, models_paths)\n",
    "    print \"Rutas cargadas en la variable 'paths_dict'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos almacenados en:\n",
      "dvd\n",
      "\tmodels/amazon/gfk/me1_dvd_0.pkl\n",
      "\tmodels/amazon/gfk/me1_dvd_1.pkl\n",
      "\tmodels/amazon/gfk/me1_dvd_2.pkl\n",
      "\tmodels/amazon/gfk/me1_dvd_3.pkl\n",
      "\tmodels/amazon/gfk/me1_dvd_4.pkl\n",
      "\tmodels/amazon/gfk/me1_dvd_5.pkl\n",
      "electronics\n",
      "\tmodels/amazon/gfk/me1_electronics_0.pkl\n",
      "\tmodels/amazon/gfk/me1_electronics_1.pkl\n",
      "\tmodels/amazon/gfk/me1_electronics_2.pkl\n",
      "\tmodels/amazon/gfk/me1_electronics_3.pkl\n",
      "\tmodels/amazon/gfk/me1_electronics_4.pkl\n",
      "\tmodels/amazon/gfk/me1_electronics_5.pkl\n",
      "books\n",
      "\tmodels/amazon/gfk/me1_books_0.pkl\n",
      "\tmodels/amazon/gfk/me1_books_1.pkl\n",
      "\tmodels/amazon/gfk/me1_books_2.pkl\n",
      "\tmodels/amazon/gfk/me1_books_3.pkl\n",
      "\tmodels/amazon/gfk/me1_books_4.pkl\n",
      "\tmodels/amazon/gfk/me1_books_5.pkl\n",
      "kitchen\n",
      "\tmodels/amazon/gfk/me1_kitchen_0.pkl\n",
      "\tmodels/amazon/gfk/me1_kitchen_1.pkl\n",
      "\tmodels/amazon/gfk/me1_kitchen_2.pkl\n",
      "\tmodels/amazon/gfk/me1_kitchen_3.pkl\n",
      "\tmodels/amazon/gfk/me1_kitchen_4.pkl\n",
      "\tmodels/amazon/gfk/me1_kitchen_5.pkl\n"
     ]
    }
   ],
   "source": [
    "print \"Modelos almacenados en:\"\n",
    "for dominio, rutas in paths_dict.items():\n",
    "    print dominio\n",
    "    for ruta in rutas:\n",
    "        print \"\\t\", ruta     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda del mejor modelo por dominio\n",
    "\n",
    "Por cada dominio se busca el mejor modelo de adaptación.\n",
    "\n",
    "Esto se obtiene adaptando los datos de entrenamiento de cada dominio por cada modelo creado y realizando Grid-Search y Cross-Validation con estos datos.\n",
    "\n",
    "El modelo que logre un mejor valor de Cross-Validation es considerado el mejor modelo para adaptar y queda guardado en un diccionario de la forma:\n",
    "\n",
    "```python\n",
    "best_models = {\n",
    "    [dominio_1] = ruta,\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    [dominio_n] = ruta,\n",
    "}\n",
    "```\n",
    "\n",
    "Este diccionario queda almacenado en la ruta:\n",
    "    models/amazon/gfk/best_models.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo mejores modelos...\n",
      "src: electronics - tgt: dvd\n",
      "score: 0.8591\n",
      "score: 0.8623\n",
      "score: 0.8649\n",
      "score: 0.8591\n",
      "score: 0.8623\n",
      "score: 0.8649\n",
      "src: electronics - tgt: kitchen\n",
      "score: 0.8511\n",
      "score: 0.8698\n",
      "score: 0.8675\n",
      "score: 0.8511\n",
      "score: 0.8702\n",
      "score: 0.8675\n",
      "src: electronics - tgt: books\n",
      "score: 0.8460\n",
      "score: 0.8608\n",
      "score: 0.8615\n",
      "score: 0.8461\n",
      "score: 0.8608\n",
      "score: 0.8616\n",
      "src: dvd - tgt: electronics\n",
      "score: 0.7714\n",
      "score: 0.8078\n",
      "score: 0.8255\n",
      "score: 0.7719\n",
      "score: 0.8078\n",
      "score: 0.8255\n",
      "src: dvd - tgt: kitchen\n",
      "score: 0.7715\n",
      "score: 0.7994\n",
      "score: 0.8248\n",
      "score: 0.7715\n",
      "score: 0.7994\n",
      "score: 0.8248\n",
      "src: dvd - tgt: books\n",
      "score: 0.7770\n",
      "score: 0.8155\n",
      "score: 0.8299\n",
      "score: 0.7770\n",
      "score: 0.8155\n",
      "score: 0.8299\n",
      "src: kitchen - tgt: electronics\n",
      "score: 0.8605\n",
      "score: 0.8839\n",
      "score: 0.8852\n",
      "score: 0.8605\n",
      "score: 0.8839\n",
      "score: 0.8852\n",
      "src: kitchen - tgt: dvd\n",
      "score: 0.8633\n",
      "score: 0.8795\n",
      "score: 0.8782\n",
      "score: 0.8633\n",
      "score: 0.8795\n",
      "score: 0.8782\n",
      "src: kitchen - tgt: books\n",
      "score: 0.8638\n",
      "score: 0.8816\n",
      "score: 0.8780\n",
      "score: 0.8638\n",
      "score: 0.8816\n",
      "score: 0.8780\n",
      "src: books - tgt: electronics\n",
      "score: 0.7787\n",
      "score: 0.7996\n",
      "score: 0.8143\n",
      "score: 0.7787\n",
      "score: 0.7996\n",
      "score: 0.8143\n",
      "src: books - tgt: dvd\n",
      "score: 0.7907\n",
      "score: 0.8133\n",
      "score: 0.8209\n",
      "score: 0.7907\n",
      "score: 0.8133\n",
      "score: 0.8209\n",
      "src: books - tgt: kitchen\n",
      "score: 0.7657\n",
      "score: 0.8112\n",
      "score: 0.8143\n",
      "score: 0.7657\n",
      "score: 0.8112\n",
      "score: 0.8143\n",
      "Rutas guardadas en  models/amazon/gfk/me1_best_models.pkl\n"
     ]
    }
   ],
   "source": [
    "best_models_paths = os.path.join(models_path, dataset_name, tipo, \"me1_best_models.pkl\")\n",
    "best_models = {}\n",
    "\n",
    "if os.path.exists(best_models_paths):\n",
    "    print \"Cargando rutas de los mejores modelos...\"\n",
    "    best_models = joblib.load(best_models_paths)\n",
    "    print \"Rutas cargadas\"\n",
    "else:\n",
    "    print \"Obteniendo mejores modelos...\"\n",
    "    pairs = list(itertools.permutations(domains, 2))\n",
    "    \n",
    "    for src, tgt in pairs:\n",
    "        print \"src: %s - tgt: %s\" % (src, tgt)\n",
    "        rutas = paths_dict[tgt]\n",
    "        \n",
    "         # se obtienen los datos del dominio\n",
    "        X_tr = np.asarray(labeled[src]['X_tr'].todense())\n",
    "        y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "        \n",
    "        mejor_score = 0\n",
    "        best_path = None\n",
    "        for ruta in rutas:\n",
    "            gfk = joblib.load(ruta)\n",
    "            X_deep = transform_gfk(X_tr, gfk)\n",
    "            \n",
    "            # se obtiene el mejor score con GridSearch\n",
    "            new_clf = get_best_score(X_deep, y_tr, classifier='SVC', n_jobs=4)\n",
    "            new_score = new_clf.best_score_\n",
    "            \n",
    "            print \"score: %.4f\" % new_score\n",
    "            # se guarda si es el mejor para el modelo\n",
    "            if new_score > mejor_score:\n",
    "                mejor_score = new_score\n",
    "                best_path = ruta\n",
    "        \n",
    "        # se guarda la ruta del mejor modelo\n",
    "        best_models[(src, tgt)] = best_path\n",
    "    \n",
    "    # se guarda el diccionario con las mejores rutas\n",
    "    joblib.dump(best_models, best_models_paths)\n",
    "    print \"Rutas guardadas en \", best_models_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dvd', 'electronics') - models/amazon/gfk/me1_electronics_2.pkl\n",
      "('books', 'kitchen') - models/amazon/gfk/me1_kitchen_2.pkl\n",
      "('books', 'dvd') - models/amazon/gfk/me1_dvd_2.pkl\n",
      "('kitchen', 'dvd') - models/amazon/gfk/me1_dvd_1.pkl\n",
      "('kitchen', 'books') - models/amazon/gfk/me1_books_1.pkl\n",
      "('books', 'electronics') - models/amazon/gfk/me1_electronics_2.pkl\n",
      "('electronics', 'dvd') - models/amazon/gfk/me1_dvd_2.pkl\n",
      "('electronics', 'kitchen') - models/amazon/gfk/me1_kitchen_4.pkl\n",
      "('kitchen', 'electronics') - models/amazon/gfk/me1_electronics_2.pkl\n",
      "('dvd', 'kitchen') - models/amazon/gfk/me1_kitchen_2.pkl\n",
      "('dvd', 'books') - models/amazon/gfk/me1_books_2.pkl\n",
      "('electronics', 'books') - models/amazon/gfk/me1_books_5.pkl\n"
     ]
    }
   ],
   "source": [
    "for dominios, ruta in best_models.items():\n",
    "    print \"%s - %s\" % (dominios, ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pruebas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 2 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 3 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 4 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 5 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 6 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 7 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 8 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 9 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 10 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 11 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 12 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "\n",
      "Pruebas completadas.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=0\n",
    "tareas = len(domains)*(len(domains)-1)\n",
    "pairs = list(itertools.permutations(domains, 2))\n",
    "\n",
    "# por cada par posible para adaptar\n",
    "for src, tgt in pairs:\n",
    "    #se carga el mejor modelo para el par de dominios\n",
    "    ruta = best_models[(src, tgt)]\n",
    "    modelo = joblib.load(ruta)\n",
    "\n",
    "    print \"Tarea %d de %d\" % (i+1, tareas)\n",
    "\n",
    "    #baseline in-domain error\n",
    "    #e_b(T,T)\n",
    "    #entrenado en dominio tgt y probado en dominio tgt\n",
    "    X_tr = np.asarray(labeled[tgt]['X_tr'].todense())\n",
    "    y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = np.asarray(labeled[tgt]['X_ts'].todense())\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se crean las rutas para cargar o crear los modelos\n",
    "    model_name = \"%s.pkl\" % (tgt)\n",
    "    model_path = os.path.join(models_path, dataset_name, \"indomain\", model_name)\n",
    "\n",
    "    #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "    svc = load_best_score(model_path, X_tr, y_tr)\n",
    "    b_error = 1-svc.score(X_ts, y_ts)\n",
    "\n",
    "    #############\n",
    "    #### GFK ####\n",
    "    #############\n",
    "    # se adaptan los dominios usando GFK\n",
    "    print \"Adaptando dominios...\"\n",
    "    X_tr = np.asarray(labeled[src]['X_tr'].todense())\n",
    "    X_tr_a = transform_gfk(X_tr, modelo)\n",
    "    y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "    X_ts = np.asarray(labeled[tgt]['X_ts'].todense())\n",
    "    X_ts_a = transform_gfk(X_ts, modelo)\n",
    "    y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "\n",
    "    # se calcula el transfer error\n",
    "    clf = get_best_score(X_tr_a, y_tr, classifier='SVC', n_jobs=4)\n",
    "    t_error = 1-clf.score(X_ts_a, y_ts)\n",
    "\n",
    "    # transfer loss (t)\n",
    "    # t_error - b_error\n",
    "    t_loss = t_error - b_error\n",
    "\n",
    "    tarea = src[0]+'->'+tgt[0]\n",
    "    df.loc[i] = ['GFK',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "\n",
    "    i += 1\n",
    "            \n",
    "print \"\\nPruebas completadas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GFK</td>\n",
       "      <td>e-&gt;d</td>\n",
       "      <td>electronics</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>25.478137</td>\n",
       "      <td>9.715243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GFK</td>\n",
       "      <td>e-&gt;k</td>\n",
       "      <td>electronics</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>10.890272</td>\n",
       "      <td>2.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GFK</td>\n",
       "      <td>e-&gt;b</td>\n",
       "      <td>electronics</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>25.273132</td>\n",
       "      <td>10.115253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GFK</td>\n",
       "      <td>d-&gt;e</td>\n",
       "      <td>dvd</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>18.610465</td>\n",
       "      <td>7.482687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GFK</td>\n",
       "      <td>d-&gt;k</td>\n",
       "      <td>dvd</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>13.232831</td>\n",
       "      <td>4.645116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GFK</td>\n",
       "      <td>d-&gt;b</td>\n",
       "      <td>dvd</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>24.518113</td>\n",
       "      <td>9.360234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GFK</td>\n",
       "      <td>k-&gt;e</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>14.045351</td>\n",
       "      <td>2.917573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GFK</td>\n",
       "      <td>k-&gt;d</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>26.888172</td>\n",
       "      <td>11.125278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GFK</td>\n",
       "      <td>k-&gt;b</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>31.618290</td>\n",
       "      <td>16.460412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GFK</td>\n",
       "      <td>b-&gt;e</td>\n",
       "      <td>books</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>23.748094</td>\n",
       "      <td>12.620316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GFK</td>\n",
       "      <td>b-&gt;d</td>\n",
       "      <td>books</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>18.765469</td>\n",
       "      <td>3.002575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GFK</td>\n",
       "      <td>b-&gt;k</td>\n",
       "      <td>books</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>15.825396</td>\n",
       "      <td>7.237681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptacion Tarea       Fuente     Objetivo  Baseline error  Transfer error  \\\n",
       "0         GFK  e->d  electronics          dvd       15.762894       25.478137   \n",
       "1         GFK  e->k  electronics      kitchen        8.587715       10.890272   \n",
       "2         GFK  e->b  electronics        books       15.157879       25.273132   \n",
       "3         GFK  d->e          dvd  electronics       11.127778       18.610465   \n",
       "4         GFK  d->k          dvd      kitchen        8.587715       13.232831   \n",
       "5         GFK  d->b          dvd        books       15.157879       24.518113   \n",
       "6         GFK  k->e      kitchen  electronics       11.127778       14.045351   \n",
       "7         GFK  k->d      kitchen          dvd       15.762894       26.888172   \n",
       "8         GFK  k->b      kitchen        books       15.157879       31.618290   \n",
       "9         GFK  b->e        books  electronics       11.127778       23.748094   \n",
       "10        GFK  b->d        books          dvd       15.762894       18.765469   \n",
       "11        GFK  b->k        books      kitchen        8.587715       15.825396   \n",
       "\n",
       "    Transfer loss  \n",
       "0        9.715243  \n",
       "1        2.302558  \n",
       "2       10.115253  \n",
       "3        7.482687  \n",
       "4        4.645116  \n",
       "5        9.360234  \n",
       "6        2.917573  \n",
       "7       11.125278  \n",
       "8       16.460412  \n",
       "9       12.620316  \n",
       "10       3.002575  \n",
       "11       7.237681  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/amazon/gfk/me1_3000.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path = os.path.join(scores_path,dataset_name, tipo, \"me1_%d.csv\" % (dims))\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
