{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#adaptacion\n",
    "from utils.adaptacion import *\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#variables para guardar los resultados\n",
    "tipo = pruebas[4]\n",
    "dataset_name = datasets[0]\n",
    "dims = dimensions[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dataset de Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sda\n",
      "amazon\n",
      "data\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print data_path\n",
    "print dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset de Twitter\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27677, 3000)\n",
      "Todos los datos disponibles obtenidos\n"
     ]
    }
   ],
   "source": [
    "# se obtienen todos los valores X disponibles para realizar adaptacion\n",
    "X = dataset_object.get_all_X()\n",
    "X = np.asarray(X)\n",
    "print X.shape\n",
    "print \"Todos los datos disponibles obtenidos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3000)\n"
     ]
    }
   ],
   "source": [
    "# se genera un sub-conjunto del dataset\n",
    "spd = 10000 / len(domains)\n",
    "\n",
    "X_small = None\n",
    "for domain in domains:\n",
    "    temp = dataset_object.get_all_domain_X(domain)\n",
    "    indexes = np.random.choice(temp.shape[0], spd)\n",
    "    \n",
    "    if X_small is None:\n",
    "        X_small = temp[indexes,:]\n",
    "    else:\n",
    "        X_small = np.vstack((X_small, temp[indexes,:]))\n",
    "\n",
    "X_small = np.asarray(X_small)\n",
    "print X_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 3000)\n",
      "(2000, 3000)\n"
     ]
    }
   ],
   "source": [
    "# se divide el dataset para los datos de entrenamiento y validacion del SDA\n",
    "X_train, X_val, _, _ = train_test_split(X_small, np.zeros(X_small.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "print X_train.shape\n",
    "print X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando modelos de adaptacion...\n",
      "pr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_0.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_0.h5\n",
      "pr: 0.300 - epochs: 25 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_1.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_1.h5\n",
      "pr: 0.300 - epochs: 50 - layers: [1500, 750]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_2.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_2.h5\n",
      "pr: 0.300 - epochs: 25 - layers: [1500, 750]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_3.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_3.h5\n",
      "pr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_4.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_4.h5\n",
      "pr: 0.500 - epochs: 25 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_5.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_5.h5\n",
      "pr: 0.500 - epochs: 50 - layers: [1500, 750]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_6.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_6.h5\n",
      "pr: 0.500 - epochs: 25 - layers: [1500, 750]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_7.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_7.h5\n",
      "pr: 0.800 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_8.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_8.h5\n",
      "pr: 0.800 - epochs: 25 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_9.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_9.h5\n",
      "pr: 0.800 - epochs: 50 - layers: [1500, 750]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_10.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_10.h5\n",
      "pr: 0.800 - epochs: 25 - layers: [1500, 750]\n",
      "\tEntrenando autoencoder...\n",
      "\tGuardando autoencoder en models/sda/amazon_ae_11.h5\n",
      "\tGuardando encoder en models/sda/amazon_e_11.h5\n",
      "\tModelos creados.\n",
      "\n",
      "\tGuardando rutas en models/sda/amazon_paths.pkl\n",
      "\n",
      "Creacion de modelos terminada.\n"
     ]
    }
   ],
   "source": [
    "sda_paths = os.path.join(models_path, tipo, \"%s_paths.pkl\" % dataset_name)\n",
    "\n",
    "if os.path.exists(sda_paths):\n",
    "    print \"Cargando rutas de modelos adaptados.\"\n",
    "    saved_paths = joblib.load(sda_paths)\n",
    "else:\n",
    "    print \"Creando modelos de adaptacion...\"\n",
    "\n",
    "    noises = [0.3 , 0.5, 0.8]\n",
    "    layers = [[int(dims/2)], [int(dims/2), int(dims/4)]]\n",
    "    epochs = [50, 25]\n",
    "\n",
    "    parametros = {\n",
    "        'noise': noises,\n",
    "        'layers': layers,\n",
    "        'epochs': epochs,\n",
    "    }\n",
    "    \n",
    "    saved_paths = sda_pseudo_grid_search(X_train, X_val, parametros, models_path, tipo, dataset_name)\n",
    "\n",
    "    print \"\\tModelos creados.\\n\"\n",
    "    \n",
    "    joblib.dump(saved_paths, sda_paths)\n",
    "    print \"\\tGuardando rutas en %s\" % sda_paths\n",
    "\n",
    "print \"\\nCreacion de modelos terminada.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'autoencoder': 'models/sda/amazon_ae_0.h5',\n",
       "  'encoder': 'models/sda/amazon_e_0.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_1.h5',\n",
       "  'encoder': 'models/sda/amazon_e_1.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_2.h5',\n",
       "  'encoder': 'models/sda/amazon_e_2.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_3.h5',\n",
       "  'encoder': 'models/sda/amazon_e_3.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_4.h5',\n",
       "  'encoder': 'models/sda/amazon_e_4.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_5.h5',\n",
       "  'encoder': 'models/sda/amazon_e_5.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_6.h5',\n",
       "  'encoder': 'models/sda/amazon_e_6.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_7.h5',\n",
       "  'encoder': 'models/sda/amazon_e_7.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_8.h5',\n",
       "  'encoder': 'models/sda/amazon_e_8.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_9.h5',\n",
       "  'encoder': 'models/sda/amazon_e_9.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_10.h5',\n",
       "  'encoder': 'models/sda/amazon_e_10.h5'},\n",
       " {'autoencoder': 'models/sda/amazon_ae_11.h5',\n",
       "  'encoder': 'models/sda/amazon_e_11.h5'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo mejor clasificador para electronics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/keras/models.py:240: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - score: 0.8331\n",
      "2 - score: 0.8100\n",
      "3 - score: 0.7812\n",
      "4 - score: 0.7831\n",
      "5 - score: 0.8075\n",
      "6 - score: 0.8000\n",
      "7 - score: 0.7719\n",
      "8 - score: 0.7850\n",
      "9 - score: 0.8131\n",
      "10 - score: 0.8275\n",
      "11 - score: 0.7650\n",
      "12 - score: 0.7712\n",
      "Guardando en models/sda/amazon_electronics_encoder.pkl\n",
      "Obteniendo mejor clasificador para dvd...\n",
      "1 - score: 0.7562\n",
      "2 - score: 0.7450\n",
      "3 - score: 0.7056\n",
      "4 - score: 0.7388\n",
      "5 - score: 0.7475\n",
      "6 - score: 0.7438\n",
      "7 - score: 0.7125\n",
      "8 - score: 0.7131\n",
      "9 - score: 0.7512\n",
      "10 - score: 0.7394\n",
      "11 - score: 0.7306\n",
      "12 - score: 0.7137\n",
      "Guardando en models/sda/amazon_dvd_encoder.pkl\n",
      "Obteniendo mejor clasificador para kitchen...\n",
      "1 - score: 0.8250\n",
      "2 - score: 0.8475\n",
      "3 - score: 0.7869\n",
      "4 - score: 0.7950\n",
      "5 - score: 0.8350\n",
      "6 - score: 0.8350\n",
      "7 - score: 0.8025\n",
      "8 - score: 0.7856\n",
      "9 - score: 0.8375\n",
      "10 - score: 0.8225\n",
      "11 - score: 0.7950\n",
      "12 - score: 0.7919\n",
      "Guardando en models/sda/amazon_kitchen_encoder.pkl\n",
      "Obteniendo mejor clasificador para books...\n",
      "1 - score: 0.7406\n",
      "2 - score: 0.7444\n",
      "3 - score: 0.6806\n",
      "4 - score: 0.7388\n",
      "5 - score: 0.7406\n",
      "6 - score: 0.7169\n",
      "7 - score: 0.6963\n",
      "8 - score: 0.7013\n",
      "9 - score: 0.7419\n",
      "10 - score: 0.7381\n",
      "11 - score: 0.7175\n",
      "12 - score: 0.7069\n",
      "Guardando en models/sda/amazon_books_encoder.pkl\n",
      "Guardando rutas en models/sda/best_amazon_paths.pkl\n",
      "\n",
      "Operacion terminada.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_sda_paths = os.path.join(models_path, tipo, \"best_%s_paths.pkl\" % dataset_name )\n",
    "if os.path.exists(best_sda_paths):\n",
    "    #se cargan las rutas de los modelos guardados\n",
    "    domain_sda_paths = joblib.load(best_sda_paths)   \n",
    "else:\n",
    "    domain_sda_paths = []\n",
    "    #por cada dominio\n",
    "    for domain in domains:\n",
    "        #por cada modelo\n",
    "        print \"Obteniendo mejor clasificador para %s...\" % domain\n",
    "        \n",
    "        i = 1\n",
    "        best_score = 0\n",
    "        best_encoder = None\n",
    "        \n",
    "        for temp_path in saved_paths:\n",
    "            #autoencoder = load_model(temp_path['autoencoder'])\n",
    "            encoder = load_model(temp_path['encoder'])\n",
    "\n",
    "        \n",
    "            X_tr = np.asarray(labeled[domain]['X_tr'].todense())\n",
    "            y_tr = np.asarray(labeled[domain]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[domain]['X_ts'].todense())\n",
    "            \n",
    "            #se adapta el dominio segun el modelo\n",
    "            X_deep = encoder.predict(X_tr)\n",
    "\n",
    "            #se crea un clasificador y se obtiene su score\n",
    "            new_clf = get_best_score(X_deep, y_tr, clasifier='SVC', n_jobs=4)\n",
    "            new_score = new_clf.best_score_\n",
    "            \n",
    "            print \"%d - score: %.4f\" % (i, new_score)\n",
    "            # se guarda si es el mejor para el modelo\n",
    "            if new_score > best_score:\n",
    "                best_score = new_score\n",
    "                best_encoder = encoder\n",
    "                \n",
    "            i= i+1\n",
    "            \n",
    "        best_encoder_path = os.path.join(models_path, tipo, \"%s_%s_encoder.pkl\" % (dataset_name, domain))\n",
    "        print \"Guardando en %s\" % best_encoder_path\n",
    "        encoder.save(best_encoder_path)\n",
    "        \n",
    "        domain_sda_paths.append(best_encoder_path)\n",
    "        \n",
    "    print \"Guardando rutas en %s\" % best_sda_paths\n",
    "    joblib.dump(domain_sda_paths, best_sda_paths)\n",
    "    \n",
    "print \"\\nOperacion terminada.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/sda/amazon_electronics_encoder.pkl',\n",
       " 'models/sda/amazon_dvd_encoder.pkl',\n",
       " 'models/sda/amazon_kitchen_encoder.pkl',\n",
       " 'models/sda/amazon_books_encoder.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_sda_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando mejor modelo para electronics\n",
      "Adaptando dominio\n",
      "Cargando mejor modelo para dvd\n",
      "Adaptando dominio\n",
      "Cargando mejor modelo para kitchen\n",
      "Adaptando dominio\n",
      "Cargando mejor modelo para books\n",
      "Adaptando dominio\n",
      "4/4 dominios adaptados\n"
     ]
    }
   ],
   "source": [
    "#diccionario para mantener los dominios adaptados\n",
    "adapted = {}\n",
    "\n",
    "i = 0\n",
    "for domain in domains:\n",
    "    best_sda_path = os.path.join(models_path, tipo, \"%s_%s_encoder.pkl\" % (dataset_name, domain))\n",
    "    \n",
    "    if os.path.exists(best_sda_path):\n",
    "        print \"Cargando mejor modelo para %s\" % domain\n",
    "        encoder = load_model(best_sda_path)\n",
    "        \n",
    "        print \"Adaptando dominio\"\n",
    "        X_tr = np.asarray(labeled[domain]['X_tr'].todense())\n",
    "        X_ts = np.asarray(labeled[domain]['X_ts'].todense())\n",
    "        \n",
    "        \n",
    "        tr_reps = encoder.predict(X_tr)\n",
    "        ts_reps = encoder.predict(X_ts)\n",
    "\n",
    "        adapted[domain] = {\n",
    "            'X_tr': tr_reps,\n",
    "            'X_ts': ts_reps\n",
    "        }\n",
    "        \n",
    "        i = i+1\n",
    "    else:\n",
    "        print \"Generar mejor modelo para %s\" % domain\n",
    "        \n",
    "print \"%d/%d dominios adaptados\" % (i, len(domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 2 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 3 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 4 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 5 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 6 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 7 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 8 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 9 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 10 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 11 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Tarea 12 de 2\n",
      "Cargando modelo existente.\n",
      "Entrenando clasificador adaptado.\n",
      "Pruebas completadas.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i = 0\n",
    "# por cada par posible para adaptar\n",
    "for src in domains:\n",
    "    for tgt in domains:\n",
    "        if src is not tgt:\n",
    "            print \"Tarea %d de 12\" % (i+1)\n",
    "            \n",
    "            #baseline in-domain error\n",
    "            #e_b(T,T)\n",
    "            #entrenado en dominio tgt y probado en dominio tgt\n",
    "            X_tr = np.asarray(labeled[tgt]['X_tr'][:, :dims].todense())\n",
    "            y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[tgt]['X_ts'][:, :dims].todense())\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            # se crean las rutas para cargar o crear los modelos\n",
    "            #model_name = \"%s_%s_%s.pkl\" % (tipo,src, tgt)\n",
    "            model_name = \"indomain_%s.pkl\" % (tgt)\n",
    "            model_path = os.path.join(models_path, dataset_name, model_name)\n",
    "            \n",
    "            #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "            svc = load_best_score(model_path, X_tr, y_tr)\n",
    "            b_error = 1-svc.score(X_ts, y_ts)\n",
    "            \n",
    "            #transfer error\n",
    "            #entrenado en dominio src y probado en dominio tgt adaptados\n",
    "            X_tr_a = adapted[src]['X_tr']\n",
    "            y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts_a = adapted[tgt]['X_ts']\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            print \"Entrenando clasificador adaptado.\"\n",
    "            svc_a = get_best_score(X_tr_a, y_tr, n_jobs=4)\n",
    "            \n",
    "            t_error = 1-svc_a.score(X_ts_a, y_ts)\n",
    "            \n",
    "            # transfer loss t\n",
    "            # t_error - b_error\n",
    "            t_loss = t_error - b_error\n",
    "            \n",
    "            tarea = src[0]+'->'+tgt[0]\n",
    "            df.loc[i] = ['SDA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "            i+=1\n",
    "\n",
    "print \"\\nPruebas completadas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SDA</td>\n",
       "      <td>e-&gt;d</td>\n",
       "      <td>electronics</td>\n",
       "      <td>dvd</td>\n",
       "      <td>23.00</td>\n",
       "      <td>36.25</td>\n",
       "      <td>13.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDA</td>\n",
       "      <td>e-&gt;k</td>\n",
       "      <td>electronics</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>17.50</td>\n",
       "      <td>26.00</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDA</td>\n",
       "      <td>e-&gt;b</td>\n",
       "      <td>electronics</td>\n",
       "      <td>books</td>\n",
       "      <td>21.25</td>\n",
       "      <td>37.50</td>\n",
       "      <td>16.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDA</td>\n",
       "      <td>d-&gt;e</td>\n",
       "      <td>dvd</td>\n",
       "      <td>electronics</td>\n",
       "      <td>20.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDA</td>\n",
       "      <td>d-&gt;k</td>\n",
       "      <td>dvd</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>17.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SDA</td>\n",
       "      <td>d-&gt;b</td>\n",
       "      <td>dvd</td>\n",
       "      <td>books</td>\n",
       "      <td>21.25</td>\n",
       "      <td>33.50</td>\n",
       "      <td>12.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SDA</td>\n",
       "      <td>k-&gt;e</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>electronics</td>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SDA</td>\n",
       "      <td>k-&gt;d</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>dvd</td>\n",
       "      <td>23.00</td>\n",
       "      <td>34.25</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SDA</td>\n",
       "      <td>k-&gt;b</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>books</td>\n",
       "      <td>21.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SDA</td>\n",
       "      <td>b-&gt;e</td>\n",
       "      <td>books</td>\n",
       "      <td>electronics</td>\n",
       "      <td>20.00</td>\n",
       "      <td>42.50</td>\n",
       "      <td>22.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SDA</td>\n",
       "      <td>b-&gt;d</td>\n",
       "      <td>books</td>\n",
       "      <td>dvd</td>\n",
       "      <td>23.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SDA</td>\n",
       "      <td>b-&gt;k</td>\n",
       "      <td>books</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>17.50</td>\n",
       "      <td>37.50</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptacion Tarea       Fuente     Objetivo  Baseline error  Transfer error  \\\n",
       "0         SDA  e->d  electronics          dvd           23.00           36.25   \n",
       "1         SDA  e->k  electronics      kitchen           17.50           26.00   \n",
       "2         SDA  e->b  electronics        books           21.25           37.50   \n",
       "3         SDA  d->e          dvd  electronics           20.00           30.00   \n",
       "4         SDA  d->k          dvd      kitchen           17.50           32.50   \n",
       "5         SDA  d->b          dvd        books           21.25           33.50   \n",
       "6         SDA  k->e      kitchen  electronics           20.00           26.00   \n",
       "7         SDA  k->d      kitchen          dvd           23.00           34.25   \n",
       "8         SDA  k->b      kitchen        books           21.25           35.25   \n",
       "9         SDA  b->e        books  electronics           20.00           42.50   \n",
       "10        SDA  b->d        books          dvd           23.00           29.00   \n",
       "11        SDA  b->k        books      kitchen           17.50           37.50   \n",
       "\n",
       "    Transfer loss  \n",
       "0           13.25  \n",
       "1            8.50  \n",
       "2           16.25  \n",
       "3           10.00  \n",
       "4           15.00  \n",
       "5           12.25  \n",
       "6            6.00  \n",
       "7           11.25  \n",
       "8           14.00  \n",
       "9           22.50  \n",
       "10           6.00  \n",
       "11          20.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/sda/amazon.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path = os.path.join(scores_path, tipo, dataset_name+\".csv\")\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
