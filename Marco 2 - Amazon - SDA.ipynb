{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#carga de datasets\n",
    "from utils.DatasetStorage import Dataset\n",
    "from utils.paths import *\n",
    "\n",
    "#clasificadores\n",
    "from utils.clasificacion import *\n",
    "\n",
    "#adaptacion\n",
    "from utils.adaptacion import sda_grid_search\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#variables para guardar los resultados\n",
    "tipo = pruebas[4]\n",
    "dataset_name = datasets[0]\n",
    "dims = dimensions[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dataset de Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sda\n",
      "amazon\n",
      "data\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print tipo\n",
    "print dataset_name\n",
    "print data_path\n",
    "print dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already splitted\n"
     ]
    }
   ],
   "source": [
    "# cargando dataset Amazon\n",
    "dataset_path = os.path.join(data_path, dataset_name+'.pkl')\n",
    "dataset_object = Dataset().load(dataset_path)\n",
    "\n",
    "dataset_object.split_dataset(test_size=0.2)\n",
    "\n",
    "labeled = dataset_object.labeled\n",
    "domains = dataset_object.domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptación\n",
    "\n",
    "## Creación de modelos de adaptación.\n",
    "\n",
    "Por cada par de dominios se entrenan distintos modelos según los parámetros establecidos.\n",
    "Al entrenar cada modelo, este es inmediatamente probado, siendo almacenado o descartado según su desempeño.\n",
    "\n",
    "Cada modelo es guardado en la ruta: models/amazon/sda/me2\\_[dominio\\_fuente]_[dominio\\_objetivo].pkl\n",
    "\n",
    "### Creación de modelos de adaptación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_src_tgt(X_src, X_tgt, test_size=0.2):\n",
    "    # se divide el dataset para los datos de entrenamiento y validacion del SDA\n",
    "    X_tr_src, X_val_src, _, _ = train_test_split(X_src, np.zeros(X_src.shape[0]), test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_tr_tgt, X_val_tgt, _, _ = train_test_split(X_tgt, np.zeros(X_tgt.shape[0]), test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train = np.concatenate((X_tr_src, X_tr_tgt))\n",
    "    X_val = np.concatenate((X_val_src, X_val_tgt))\n",
    "    \n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptando entre:\n",
      "1) electronics - dvd\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.885\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.892\n",
      "\n",
      "\tMejor modelo: 0.892\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_electronics_dvd.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_electronics_dvd.h5\n",
      "\n",
      "2) electronics - kitchen\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.901\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.888\n",
      "\n",
      "\tMejor modelo: 0.901\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_electronics_kitchen.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_electronics_kitchen.h5\n",
      "\n",
      "3) electronics - books\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.879\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.883\n",
      "\n",
      "\tMejor modelo: 0.883\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_electronics_books.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_electronics_books.h5\n",
      "\n",
      "4) dvd - electronics\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.833\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.821\n",
      "\n",
      "\tMejor modelo: 0.833\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_dvd_electronics.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_dvd_electronics.h5\n",
      "\n",
      "5) dvd - kitchen\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.820\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.839\n",
      "\n",
      "\tMejor modelo: 0.839\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_dvd_kitchen.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_dvd_kitchen.h5\n",
      "\n",
      "6) dvd - books\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.829\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.820\n",
      "\n",
      "\tMejor modelo: 0.829\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_dvd_books.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_dvd_books.h5\n",
      "\n",
      "7) kitchen - electronics\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.896\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.902\n",
      "\n",
      "\tMejor modelo: 0.902\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_kitchen_electronics.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_kitchen_electronics.h5\n",
      "\n",
      "8) kitchen - dvd\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.899\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.897\n",
      "\n",
      "\tMejor modelo: 0.899\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_kitchen_dvd.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_kitchen_dvd.h5\n",
      "\n",
      "9) kitchen - books\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.894\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.891\n",
      "\n",
      "\tMejor modelo: 0.894\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_kitchen_books.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_kitchen_books.h5\n",
      "\n",
      "10) books - electronics\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.831\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.823\n",
      "\n",
      "\tMejor modelo: 0.831\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_books_electronics.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_books_electronics.h5\n",
      "\n",
      "11) books - dvd\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.800\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.799\n",
      "\n",
      "\tMejor modelo: 0.800\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_books_dvd.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_books_dvd.h5\n",
      "\n",
      "12) books - kitchen\n",
      "\tpr: 0.300 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.816\n",
      "\n",
      "\tpr: 0.500 - epochs: 50 - layers: [1500]\n",
      "\tEntrenando autoencoder...\n",
      "\t0.821\n",
      "\n",
      "\tMejor modelo: 0.821\n",
      "\tGuardando autoencoder en models/amazon/sda/me2_ae_books_kitchen.h5\n",
      "\tGuardando encoder en models/amazon/sda/me2_e_books_kitchen.h5\n",
      "\n",
      "\n",
      "Adaptaciones completadas\n"
     ]
    }
   ],
   "source": [
    "models_paths = os.path.join(models_path, dataset_name, tipo, 'me2_models_paths.pkl')\n",
    "\n",
    "parameters = {\n",
    "    'noises': [0.3 , 0.5, 0.8],\n",
    "    'layers': [[int(dims/2)], [int(dims/2), int(dims/4)]],\n",
    "    'epochs': [50, 25],\n",
    "    #'noises': [0.3, 0.5],\n",
    "    #'layers': [[int(dims/2)]],\n",
    "    #'epochs': [50],\n",
    "}\n",
    "\n",
    "i = 1\n",
    "\n",
    "#por cada par se entrena un adaptador y se guarda el que mejor resultados entrega\n",
    "print \"Adaptando entre:\"\n",
    "for src in domains:\n",
    "    for tgt in domains:\n",
    "        if src is not tgt:\n",
    "            print \"%d) %s - %s\" % (i, src, tgt)\n",
    "            X_src = np.asarray(labeled[src]['X_tr'].todense())\n",
    "            y_src = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "\n",
    "            X_tgt = np.asarray(labeled[tgt]['X_tr'].todense())\n",
    "            \n",
    "            X_train, X_val = split_src_tgt(X_src, X_tgt, test_size=0.2)\n",
    "            \n",
    "            best_autoencoder, best_encoder, score = sda_grid_search(X_train, X_val, X_src, y_src, parameters, n_jobs=4)\n",
    "            print \"\\tMejor modelo: %.3f\" % score\n",
    "            \n",
    "            folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "            prefix_ae = \"me2_ae_\" + src + \"_\" + tgt + \".h5\"\n",
    "            prefix_e = \"me2_e_\" + src + \"_\" + tgt + \".h5\"\n",
    "            \n",
    "            best_ae_save_path = os.path.join(folder_path, prefix_ae)\n",
    "            best_e_save_path = os.path.join(folder_path, prefix_e)\n",
    "            \n",
    "            print \"\\tGuardando autoencoder en %s\" % best_ae_save_path\n",
    "            best_autoencoder.save(best_ae_save_path)\n",
    "                \n",
    "            print \"\\tGuardando encoder en %s\\n\" % best_e_save_path\n",
    "            best_encoder.save(best_e_save_path)\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "print \"\\nAdaptaciones completadas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/env_memoria/lib/python2.7/site-packages/keras/models.py:240: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 2 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 3 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 4 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 5 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 6 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 7 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 8 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 9 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 10 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 11 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "Tarea 12 de 12\n",
      "Cargando modelo existente.\n",
      "Adaptando dominios...\n",
      "\n",
      "Pruebas completadas.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=dataframe_columns)\n",
    "\n",
    "i=1\n",
    "tareas = len(domains)*(len(domains)-1)\n",
    "\n",
    "# por cada par posible para adaptar\n",
    "for src in domains:\n",
    "    for tgt in domains:\n",
    "        if src is not tgt:\n",
    "            print \"Tarea %d de %d\" % (i, tareas)\n",
    "            \n",
    "            #baseline in-domain error\n",
    "            #e_b(T,T)\n",
    "            #entrenado en dominio tgt y probado en dominio tgt\n",
    "            X_tr = np.asarray(labeled[tgt]['X_tr'].todense())\n",
    "            y_tr = np.asarray(labeled[tgt]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[tgt]['X_ts'].todense())\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            # se crean las rutas para cargar o crear los modelos\n",
    "            model_name = \"%s.pkl\" % (tgt)\n",
    "            model_path = os.path.join(models_path, dataset_name, \"indomain\", model_name)\n",
    "            \n",
    "            #Se realiza una clasificacion, estimando los parametros mediante cv\n",
    "            svc = load_best_score(model_path, X_tr, y_tr)\n",
    "            b_error = 1-svc.score(X_ts, y_ts)\n",
    "            \n",
    "            #############\n",
    "            #### SDA ####\n",
    "            #############\n",
    "            # se adaptan los dominios usando SDA\n",
    "            print \"Adaptando dominios...\"\n",
    "            folder_path = os.path.join(models_path, dataset_name, tipo)\n",
    "            prefix_e = \"me2_e_\" + src + \"_\" + tgt + \".h5\"\n",
    "            best_e_save_path = os.path.join(folder_path, prefix_e)\n",
    "            \n",
    "            best_encoder = load_model(best_e_save_path)\n",
    "            \n",
    "            \n",
    "            X_tr = np.asarray(labeled[src]['X_tr'].todense())\n",
    "            X_tr_a = best_encoder.predict(X_tr)\n",
    "            y_tr = np.asarray(labeled[src]['y_tr'].todense()).argmax(axis=1)\n",
    "            \n",
    "            X_ts = np.asarray(labeled[tgt]['X_ts'].todense())\n",
    "            X_ts_a = best_encoder.predict(X_ts)\n",
    "            y_ts = np.asarray(labeled[tgt]['y_ts'].todense()).argmax(axis=1)\n",
    "            \n",
    "            clf = get_best_score(X_tr_a, y_tr, classifier='SVC', n_jobs=4)\n",
    "            t_error = 1-clf.score(X_ts_a, y_ts)\n",
    "            \n",
    "            \n",
    "            # transfer loss t\n",
    "            # t_error - b_error\n",
    "            t_loss = t_error - b_error\n",
    "            \n",
    "            tarea = src[0]+'->'+tgt[0]\n",
    "            df.loc[i] = ['SDA',tarea,src,tgt,b_error*100,t_error*100, t_loss*100]\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "print \"\\nPruebas completadas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptacion</th>\n",
       "      <th>Tarea</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Objetivo</th>\n",
       "      <th>Baseline error</th>\n",
       "      <th>Transfer error</th>\n",
       "      <th>Transfer loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDA</td>\n",
       "      <td>e-&gt;d</td>\n",
       "      <td>electronics</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>29.055726</td>\n",
       "      <td>13.292832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDA</td>\n",
       "      <td>e-&gt;k</td>\n",
       "      <td>electronics</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>13.082827</td>\n",
       "      <td>4.495112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDA</td>\n",
       "      <td>e-&gt;b</td>\n",
       "      <td>electronics</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>26.238156</td>\n",
       "      <td>11.080277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDA</td>\n",
       "      <td>d-&gt;e</td>\n",
       "      <td>dvd</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>28.355709</td>\n",
       "      <td>17.227931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SDA</td>\n",
       "      <td>d-&gt;k</td>\n",
       "      <td>dvd</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>17.735443</td>\n",
       "      <td>9.147729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SDA</td>\n",
       "      <td>d-&gt;b</td>\n",
       "      <td>dvd</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>24.383110</td>\n",
       "      <td>9.225231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SDA</td>\n",
       "      <td>k-&gt;e</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>14.970374</td>\n",
       "      <td>3.842596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SDA</td>\n",
       "      <td>k-&gt;d</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>29.108228</td>\n",
       "      <td>13.345334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SDA</td>\n",
       "      <td>k-&gt;b</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>books</td>\n",
       "      <td>15.157879</td>\n",
       "      <td>30.588265</td>\n",
       "      <td>15.430386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SDA</td>\n",
       "      <td>b-&gt;e</td>\n",
       "      <td>books</td>\n",
       "      <td>electronics</td>\n",
       "      <td>11.127778</td>\n",
       "      <td>29.380735</td>\n",
       "      <td>18.252956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SDA</td>\n",
       "      <td>b-&gt;d</td>\n",
       "      <td>books</td>\n",
       "      <td>dvd</td>\n",
       "      <td>15.762894</td>\n",
       "      <td>21.755544</td>\n",
       "      <td>5.992650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SDA</td>\n",
       "      <td>b-&gt;k</td>\n",
       "      <td>books</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>8.587715</td>\n",
       "      <td>20.820521</td>\n",
       "      <td>12.232806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptacion Tarea       Fuente     Objetivo  Baseline error  Transfer error  \\\n",
       "1         SDA  e->d  electronics          dvd       15.762894       29.055726   \n",
       "2         SDA  e->k  electronics      kitchen        8.587715       13.082827   \n",
       "3         SDA  e->b  electronics        books       15.157879       26.238156   \n",
       "4         SDA  d->e          dvd  electronics       11.127778       28.355709   \n",
       "5         SDA  d->k          dvd      kitchen        8.587715       17.735443   \n",
       "6         SDA  d->b          dvd        books       15.157879       24.383110   \n",
       "7         SDA  k->e      kitchen  electronics       11.127778       14.970374   \n",
       "8         SDA  k->d      kitchen          dvd       15.762894       29.108228   \n",
       "9         SDA  k->b      kitchen        books       15.157879       30.588265   \n",
       "10        SDA  b->e        books  electronics       11.127778       29.380735   \n",
       "11        SDA  b->d        books          dvd       15.762894       21.755544   \n",
       "12        SDA  b->k        books      kitchen        8.587715       20.820521   \n",
       "\n",
       "    Transfer loss  \n",
       "1       13.292832  \n",
       "2        4.495112  \n",
       "3       11.080277  \n",
       "4       17.227931  \n",
       "5        9.147729  \n",
       "6        9.225231  \n",
       "7        3.842596  \n",
       "8       13.345334  \n",
       "9       15.430386  \n",
       "10      18.252956  \n",
       "11       5.992650  \n",
       "12      12.232806  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en scores/amazon/sda/me2_3000.csv\n",
      "Resultados guardados.\n"
     ]
    }
   ],
   "source": [
    "new_scores_path = os.path.join(scores_path,dataset_name, tipo, \"me2_%d.csv\" % (dims))\n",
    "\n",
    "print \"Guardando en %s\" % new_scores_path\n",
    "df.to_csv(new_scores_path, columns=df.columns)\n",
    "print \"Resultados guardados.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
